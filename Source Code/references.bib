
@book{dey_differential_2021,
	address = {London},
	title = {Differential {Equations}: {A} {Linear} {Algebra} {Approach}},
	isbn = {978-1-00-320598-2},
	shorttitle = {Differential {Equations}},
	abstract = {Differential Equations: A Linear Algebra Approach follows an innovative approach of inculcating linear algebra and elementary functional analysis in the backdrop of even the simple methods of solving ordinary differential equations. The contents of the book have been made user-friendly through concise useful theoretical discussions and numerous illustrative examples practical and pathological.},
	publisher = {CRC Press},
	author = {Dey, Anindya},
	month = sep,
	year = {2021},
	doi = {10.1201/9781003205982},
}

@misc{ju_flooding_2024,
	title = {Flooding {Spread} of {Manipulated} {Knowledge} in {LLM}-{Based} {Multi}-{Agent} {Communities}},
	url = {http://arxiv.org/abs/2407.07791},
	doi = {10.48550/arXiv.2407.07791},
	abstract = {The rapid adoption of large language models (LLMs) in multi-agent systems has highlighted their impressive capabilities in various applications, such as collaborative problem-solving and autonomous negotiation. However, the security implications of these LLM-based multi-agent systems have not been thoroughly investigated, particularly concerning the spread of manipulated knowledge. In this paper, we investigate this critical issue by constructing a detailed threat model and a comprehensive simulation environment that mirrors real-world multi-agent deployments in a trusted platform. Subsequently, we propose a novel two-stage attack method involving Persuasiveness Injection and Manipulated Knowledge Injection to systematically explore the potential for manipulated knowledge (i.e., counterfactual and toxic knowledge) spread without explicit prompt manipulation. Our method leverages the inherent vulnerabilities of LLMs in handling world knowledge, which can be exploited by attackers to unconsciously spread fabricated information. Through extensive experiments, we demonstrate that our attack method can successfully induce LLM-based agents to spread both counterfactual and toxic knowledge without degrading their foundational capabilities during agent communication. Furthermore, we show that these manipulations can persist through popular retrieval-augmented generation frameworks, where several benign agents store and retrieve manipulated chat histories for future interactions. This persistence indicates that even after the interaction has ended, the benign agents may continue to be influenced by manipulated knowledge. Our findings reveal significant security risks in LLM-based multi-agent systems, emphasizing the imperative need for robust defenses against manipulated knowledge spread, such as introducing ``guardian'' agents and advanced fact-checking tools.},
	urldate = {2024-09-11},
	publisher = {arXiv},
	author = {Ju, Tianjie and Wang, Yiting and Ma, Xinbei and Cheng, Pengzhou and Zhao, Haodong and Wang, Yulong and Liu, Lifeng and Xie, Jian and Zhang, Zhuosheng and Liu, Gongshen},
	month = jul,
	year = {2024},
	note = {arXiv:2407.07791 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{barman_dark_2024,
	title = {The {Dark} {Side} of {Language} {Models}: {Exploring} the {Potential} of {LLMs} in {Multimedia} {Disinformation} {Generation} and {Dissemination}},
	volume = {16},
	issn = {2666-8270},
	shorttitle = {The {Dark} {Side} of {Language} {Models}},
	url = {https://www.sciencedirect.com/science/article/pii/S2666827024000215},
	doi = {10.1016/j.mlwa.2024.100545},
	abstract = {Disinformation - the deliberate spread of false or misleading information poses a significant threat to our society by undermining trust, exacerbating polarization, and manipulating public opinion. With the rapid advancement of artificial intelligence and the growing prominence of large language models (LLMs) such as ChatGPT, new avenues for the dissemination of disinformation are emerging. This review paper explores the potential of LLMs to initiate the generation of multi-media disinformation, encompassing text, images, audio, and video. We begin by examining the capabilities of LLMs, highlighting their potential to create compelling, context-aware content that can be weaponized for malicious purposes. Subsequently, we examine the nature of disinformation and the various mechanisms through which it spreads in the digital landscape. Utilizing these advanced models, malicious actors can automate and scale up disinformation effectively. We describe a theoretical pipeline for creating and disseminating disinformation on social media. Existing interventions to combat disinformation are also reviewed. While these efforts have shown success, we argue that they need to be strengthened to effectively counter the escalating threat posed by LLMs. Digital platforms have, unfortunately, enabled malicious actors to extend the reach of disinformation. The advent of LLMs poses an additional concern as they can be harnessed to significantly amplify the velocity, variety, and volume of disinformation. Thus, this review proposes augmenting current interventions with AI tools like LLMs, capable of assessing information more swiftly and comprehensively than human fact-checkers. This paper illuminates the dark side of LLMs and highlights their potential to be exploited as disinformation dissemination tools.},
	urldate = {2024-09-11},
	journal = {Machine Learning with Applications},
	author = {Barman, Dipto and Guo, Ziyi and Conlan, Owen},
	month = jun,
	year = {2024},
	keywords = {ChatGPT, Disinformation, Information quality, Llms, Mitigation},
	pages = {100545},
}

@misc{brigham_breaking_2024,
	title = {Breaking {News}: {Case} {Studies} of {Generative} {AI}'s {Use} in {Journalism}},
	shorttitle = {Breaking {News}},
	url = {http://arxiv.org/abs/2406.13706},
	doi = {10.48550/arXiv.2406.13706},
	abstract = {Journalists are among the many users of large language models (LLMs). To better understand the journalist-AI interactions, we conduct a study of LLM usage by two news agencies through browsing the WildChat dataset, identifying candidate interactions, and verifying them by matching to online published articles. Our analysis uncovers instances where journalists provide sensitive material such as confidential correspondence with sources or articles from other agencies to the LLM as stimuli and prompt it to generate articles, and publish these machine-generated articles with limited intervention (median output-publication ROUGE-L of 0.62). Based on our findings, we call for further research into what constitutes responsible use of AI, and the establishment of clear guidelines and best practices on using LLMs in a journalistic context.},
	urldate = {2024-09-10},
	publisher = {arXiv},
	author = {Brigham, Natalie Grace and Gao, Chongjiu and Kohno, Tadayoshi and Roesner, Franziska and Mireshghallah, Niloofar},
	month = jun,
	year = {2024},
	note = {arXiv:2406.13706 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@misc{noauthor_introducing_2024,
	title = {Introducing {ChatGPT} {Edu}},
	url = {https://openai.com/index/introducing-chatgpt-edu/},
	abstract = {An affordable offering for universities to responsibly bring AI to campus.},
	language = {en-US},
	month = may,
	year = {2024},
}

@inproceedings{orenstrakh_detecting_2024,
	title = {Detecting {LLM}-{Generated} {Text} in {Computing} {Education}: {Comparative} {Study} for {ChatGPT} {Cases}},
	shorttitle = {Detecting {LLM}-{Generated} {Text} in {Computing} {Education}},
	url = {https://ieeexplore.ieee.org/abstract/document/10633247},
	doi = {10.1109/COMPSAC61105.2024.00027},
	abstract = {Due to the recent improvements and wide availability of Large Language Models (LLMs), they have posed a serious threat to academic integrity in education. Modern LLM-generated text detectors attempt to combat the problem by offering educators with services to assess whether some text is LLM-generated. In this work, we have collected 124 submissions from computer science students before the creation of ChatGPT. We then generated 40 ChatGPT submissions. We used this data to evaluate eight publicly-available LLM-generated text detectors through the measures of accuracy, false positives, and resilience. Our results find that Copy Leaks is the most accurate LLM-generated text detector, G PTKit is the best LLM-generated text detector to reduce false positives, and GLTR is the most resilient LLM-generated text detector. We note that all LLM-generated text detectors are less accurate with code, other languages (aside from English), and after the use of paraphrasing tools.},
	urldate = {2024-09-10},
	booktitle = {2024 {IEEE} 48th {Annual} {Computers}, {Software}, and {Applications} {Conference} ({COMPSAC})},
	author = {Orenstrakh, Michael Sheinman and Karnalim, Oscar and Suárez, Carlos Aníbal and Liut, Michael},
	month = jul,
	year = {2024},
	note = {ISSN: 2836-3795},
	keywords = {AI Detectors, Academic Integrity, Accuracy, ChatGPT, Chatbots, Detectors, Education, GPT, Large Language Models, Large language models, Measurement, Plagiarism},
	pages = {121--126},
}

@misc{urman_silence_2023,
	title = {The {Silence} of the {LLMs}: {Cross}-{Lingual} {Analysis} of {Political} {Bias} and {False} {Information} {Prevalence} in {ChatGPT}, {Google} {Bard}, and {Bing} {Chat}},
	shorttitle = {The {Silence} of the {LLMs}},
	url = {https://osf.io/q9v8f},
	doi = {10.31219/osf.io/q9v8f},
	abstract = {This article presents a comparative analysis of political bias in the outputs of three Large Language Model (LLM)-based chatbots - ChatGPT, Bing Chat, and Bard - in response to political queries concerning the authoritarian regime in Russia. We investigate whether safeguards implemented in these chatbots contribute to the censorship of information that is viewed as harmful by the regime, in particular information about Vladimir Putin and the Russian war against Ukraine, and whether these safeguards enable the generation of false claims, in particular in relation to the regime's internal and external opponents. To detect whether LLM safeguards reiterate political bias, the article compares the outputs of prompts focusing on Putin's regime and the ones dealing with the Russian opposition and the US and Ukrainian politicians. It also examines whether the degree of bias varies depending on the language of the prompt and compares outputs concerning political personalities and issues across three languages: Russian, Ukrainian, and English. The results reveal significant disparities in how individual chatbots withhold politics-related information or produce false claims in relation to it. Notably, Bard consistently refused to respond to queries about Vladimir Putin in Russian, even when the relevant information was accessible via Google Search, and generally followed the censorship guidelines that, according to Yandex-related data leaks, were issued by the Russian authorities. In terms of false claims, we find substantial variation across languages with Ukrainian and Russian prompts generating false information more often and Bard being more prone to produce false claims in relation to Russian regime opponents (e.g., Navalny or Zelenskyy) than other chatbots. This research aims to stimulate further dialogue and research on developing safeguards against the misuse of LLMs outside of democratic environments.},
	language = {en-us},
	urldate = {2024-09-09},
	publisher = {OSF},
	author = {Urman, Aleksandra and Makhortykh, Mykola},
	month = sep,
	year = {2023},
}

@misc{bai_hallucination_2024,
	title = {Hallucination of {Multimodal} {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Hallucination of {Multimodal} {Large} {Language} {Models}},
	url = {https://arxiv.org/abs/2404.18930v1},
	abstract = {This survey presents a comprehensive analysis of the phenomenon of hallucination in multimodal large language models (MLLMs), also known as Large Vision-Language Models (LVLMs), which have demonstrated significant advancements and remarkable abilities in multimodal tasks. Despite these promising developments, MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination, which poses substantial obstacles to their practical deployment and raises concerns regarding their reliability in real-world applications. This problem has attracted increasing attention, prompting efforts to detect and mitigate such inaccuracies. We review recent advances in identifying, evaluating, and mitigating these hallucinations, offering a detailed overview of the underlying causes, evaluation benchmarks, metrics, and strategies developed to address this issue. Additionally, we analyze the current challenges and limitations, formulating open questions that delineate potential pathways for future research. By drawing the granular classification and landscapes of hallucination causes, evaluation benchmarks, and mitigation methods, this survey aims to deepen the understanding of hallucinations in MLLMs and inspire further advancements in the field. Through our thorough and in-depth review, we contribute to the ongoing dialogue on enhancing the robustness and reliability of MLLMs, providing valuable insights and resources for researchers and practitioners alike. Resources are available at: https://github.com/showlab/Awesome-MLLM-Hallucination.},
	language = {en},
	urldate = {2024-09-05},
	publisher = {arXiv},
	author = {Bai, Zechen and Wang, Pichao and Xiao, Tianjun and He, Tong and Han, Zongbo and Zhang, Zheng and Shou, Mike Zheng},
	month = apr,
	year = {2024},
}

@misc{bai_hallucination_2024-1,
	title = {Hallucination of {Multimodal} {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Hallucination of {Multimodal} {Large} {Language} {Models}},
	url = {https://arxiv.org/abs/2404.18930v1},
	abstract = {This survey presents a comprehensive analysis of the phenomenon of hallucination in multimodal large language models (MLLMs), also known as Large Vision-Language Models (LVLMs), which have demonstrated significant advancements and remarkable abilities in multimodal tasks. Despite these promising developments, MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination, which poses substantial obstacles to their practical deployment and raises concerns regarding their reliability in real-world applications. This problem has attracted increasing attention, prompting efforts to detect and mitigate such inaccuracies. We review recent advances in identifying, evaluating, and mitigating these hallucinations, offering a detailed overview of the underlying causes, evaluation benchmarks, metrics, and strategies developed to address this issue. Additionally, we analyze the current challenges and limitations, formulating open questions that delineate potential pathways for future research. By drawing the granular classification and landscapes of hallucination causes, evaluation benchmarks, and mitigation methods, this survey aims to deepen the understanding of hallucinations in MLLMs and inspire further advancements in the field. Through our thorough and in-depth review, we contribute to the ongoing dialogue on enhancing the robustness and reliability of MLLMs, providing valuable insights and resources for researchers and practitioners alike. Resources are available at: https://github.com/showlab/Awesome-MLLM-Hallucination.},
	language = {en},
	urldate = {2024-09-05},
	journal = {arXiv.org},
	author = {Bai, Zechen and Wang, Pichao and Xiao, Tianjun and He, Tong and Han, Zongbo and Zhang, Zheng and Shou, Mike Zheng},
	month = apr,
	year = {2024},
}

@inproceedings{liu_preventing_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Preventing and {Detecting} {Misinformation} {Generated} by {Large} {Language} {Models}},
	isbn = {9798400704314},
	url = {https://dl.acm.org/doi/10.1145/3626772.3661377},
	doi = {10.1145/3626772.3661377},
	abstract = {As large language models (LLMs) become increasingly capable and widely deployed, the risk of them generating misinformation poses a critical challenge. Misinformation from LLMs can take various forms, from factual errors due to hallucination to intentionally deceptive content, and can have severe consequences in high-stakes domains.This tutorial covers comprehensive strategies to prevent and detect misinformation generated by LLMs. We first introduce the types of misinformation LLMs can produce and their root causes. We then explore two broad categories: Preventing misinformation generation: a) AI alignment training techniques to reduce LLMs' propensity for misinformation and refuse malicious instructions during model training. b) Training-free mitigation methods like prompt guardrails, retrieval-augmented generation (RAG), and decoding strategies to curb misinformation at inference time. Detecting misinformation after generation, including a) using LLMs themselves to detect misinformation through embedded knowledge or retrieval-enhanced judgments, and b) distinguishing LLM-generated text from human-written text through black-box approaches (e.g., classifiers, probability analysis) and white-box approaches (e.g., watermarking). We also discuss the challenges and limitations of detecting LLM-generated misinformation.},
	urldate = {2024-09-05},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Aiwei and Sheng, Qiang and Hu, Xuming},
	month = jul,
	year = {2024},
	pages = {3001--3004},
}

@misc{yu_fake_2024,
	title = {Fake {Artificial} {Intelligence} {Generated} {Contents} ({FAIGC}): {A} {Survey} of {Theories}, {Detection} {Methods}, and {Opportunities}},
	shorttitle = {Fake {Artificial} {Intelligence} {Generated} {Contents} ({FAIGC})},
	url = {http://arxiv.org/abs/2405.00711},
	doi = {10.48550/arXiv.2405.00711},
	abstract = {In recent years, generative artificial intelligence models, represented by Large Language Models (LLMs) and Diffusion Models (DMs), have revolutionized content production methods. These artificial intelligence-generated content (AIGC) have become deeply embedded in various aspects of daily life and work. However, these technologies have also led to the emergence of Fake Artificial Intelligence Generated Content (FAIGC), posing new challenges in distinguishing genuine information. It is crucial to recognize that AIGC technology is akin to a double-edged sword; its potent generative capabilities, while beneficial, also pose risks for the creation and dissemination of FAIGC. In this survey, We propose a new taxonomy that provides a more comprehensive breakdown of the space of FAIGC methods today. Next, we explore the modalities and generative technologies of FAIGC. We introduce FAIGC detection methods and summarize the related benchmark from various perspectives. Finally, we discuss outstanding challenges and promising areas for future research.},
	urldate = {2024-09-05},
	publisher = {arXiv},
	author = {Yu, Xiaomin and Wang, Yezhaohui and Chen, Yanfang and Tao, Zhen and Xi, Dinghao and Song, Shichao and Niu, Simin and Li, Zhiyu},
	month = may,
	year = {2024},
	note = {arXiv:2405.00711 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@misc{chukamphaeng_brief_2023,
	title = {A {Brief} {Overview} of {Hallucination} in {LLM}},
	url = {https://medium.com/scb-datax/a-brief-overview-of-hallucination-in-llm-848716229d6a},
	abstract = {Large Language Models (LLMs) have shown the impressive capability to understand human language and effectively tackling a wide range of…},
	language = {en},
	urldate = {2024-09-04},
	journal = {SCB DataX},
	author = {Chukamphaeng, Nut},
	month = oct,
	year = {2023},
}

@misc{ye_cognitive_2023,
	title = {Cognitive {Mirage}: {A} {Review} of {Hallucinations} in {Large} {Language} {Models}},
	shorttitle = {Cognitive {Mirage}},
	url = {http://arxiv.org/abs/2309.06794},
	doi = {10.48550/arXiv.2309.06794},
	abstract = {As large language models continue to develop in the field of AI, text generation systems are susceptible to a worrisome phenomenon known as hallucination. In this study, we summarize recent compelling insights into hallucinations in LLMs. We present a novel taxonomy of hallucinations from various text generation tasks, thus provide theoretical insights, detection methods and improvement approaches. Based on this, future research directions are proposed. Our contribution are threefold: (1) We provide a detailed and complete taxonomy for hallucinations appearing in text generation tasks; (2) We provide theoretical analyses of hallucinations in LLMs and provide existing detection and improvement methods; (3) We propose several research directions that can be developed in the future. As hallucinations garner significant attention from the community, we will maintain updates on relevant research progress.},
	urldate = {2024-09-04},
	publisher = {arXiv},
	author = {Ye, Hongbin and Liu, Tong and Zhang, Aijia and Hua, Wei and Jia, Weiqiang},
	month = sep,
	year = {2023},
	note = {arXiv:2309.06794 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{kaplan_scaling_2020,
	title = {Scaling {Laws} for {Neural} {Language} {Models}},
	url = {http://arxiv.org/abs/2001.08361},
	doi = {10.48550/arXiv.2001.08361},
	abstract = {We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.},
	urldate = {2024-09-04},
	publisher = {arXiv},
	author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
	month = jan,
	year = {2020},
	note = {arXiv:2001.08361 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2024-09-04},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{limbu_journey_2024,
	title = {A {Journey} {Through} the {History} of {Deep} {Learning}},
	url = {https://medium.com/@limbusapna3/a-journey-through-the-history-of-deep-learning-7033f1ff21c0},
	abstract = {Deep learning is a subset of machine learning that deals with algorithms inspired by the structure and function of the human brain. Deep…},
	language = {en},
	journal = {Medium},
	author = {Limbu, Sapna},
	month = may,
	year = {2024},
}

@book{wooldridge_brief_2021,
	address = {New York},
	title = {A {Brief} {History} of {Artificial} {Intelligence}: {What} {It} {Is}, {Where} {We} {Are}, and {Where} {We} {Are} {Going}},
	isbn = {978-1-250-77074-5},
	shorttitle = {A {Brief} {History} of {Artificial} {Intelligence}},
	abstract = {From Oxford's leading AI researcher comes a fun and accessible tour through the history and future of one of the most cutting edge and misunderstood field in science: Artificial IntelligenceThe somewhat ill-defined long-term aim of AI is to build machines that are conscious, self-aware, and sentient; machines capable of the kind of intelligent autonomous action that currently only people are capable of. As an AI researcher with 25 years of experience, professor Mike Wooldridge has learned to be obsessively cautious about such claims, while still promoting an intense optimism about the future of the field. There have been genuine scientific breakthroughs that have made AI systems possible in the past decade that the founders of the field would have hailed as miraculous. Driverless cars and automated translation tools are just two examples of AI technologies that have become a practical, everyday reality in the past few years, and which will have a huge impact on our world.While the dream of conscious machines remains, Professor Wooldridge believes, a distant prospect, the floodgates for AI have opened. Wooldridge's A Brief History of Artificial Intelligence is an exciting romp through the history of this groundbreaking field--a one-stop-shop for AI's past, present, and world-changing future.},
	language = {English},
	publisher = {Flatiron Books},
	author = {Wooldridge, Michael},
	month = jan,
	year = {2021},
}

@book{kuttler_elementary_2017,
	address = {New York},
	title = {Elementary {Differential} {Equations}},
	isbn = {978-1-315-18313-8},
	abstract = {Elementary Differential Equations presents the standard material in a first course on diﬀerential equations, including all standard methods which have been a part of the subject since the time of Newton and the Bernoulli brothers. The emphasis in this book is on theory and methods and diﬀerential equations as a part of analysis.

Diﬀerential equations is worth studying, rather than merely some recipes to be used in physical science. The text gives substantial emphasis to methods which are generally presented ﬁrst with theoretical considerations following. Essentially all proofs of the theorems used are included, making the book more useful as a reference.

The book mentions the main computer algebra systems, yet the emphasis is placed on MATLAB and numerical methods which include graphing the solutions and obtaining tables of values. 

Featured applications are easily understood. Complete explanations of the mathematics and emphasis on methods for ﬁnding solutions are included.},
	publisher = {Chapman and Hall/CRC},
	author = {Kuttler, Kenneth},
	month = nov,
	year = {2017},
	doi = {10.1201/9781315183138},
}

@misc{noauthor_eng_nodate,
	title = {{ENG} {Math}},
	url = {https://www.overleaf.com/project/66a20e93f7054bc3be8c6aed},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2024-08-30},
}

@incollection{krantz_introduction_2013,
	address = {New York, NY},
	title = {Introduction to the {Implicit} {Function} {Theorem}},
	isbn = {978-1-4614-5981-1},
	url = {https://doi.org/10.1007/978-1-4614-5981-1_1},
	abstract = {To the beginning student of calculus, a function is given by an analytic expression such as 1.1\$\$f(x)=x{\textasciicircum}3+2x{\textasciicircum}2-x-3,\$\$1.2\$\$g(y)={\textbackslash}sqrt\{y{\textasciicircum}2+1\}\$\$or 1.3\$\$h(t)=cos(2{\textbackslash}pi t)\$\$},
	language = {en},
	urldate = {2024-08-23},
	booktitle = {The {Implicit} {Function} {Theorem}: {History}, {Theory}, and {Applications}},
	publisher = {Springer},
	author = {Krantz, Steven G. and Parks, Harold R.},
	editor = {Krantz, Steven G. and Parks, Harold R.},
	year = {2013},
	doi = {10.1007/978-1-4614-5981-1_1},
	keywords = {Celestial Mechanic, Differentiable Function, Implicit Function Theorem, Linear Algebra, Tangent Plane},
	pages = {1--12},
}

@article{fiorenza_generalizations_2024,
	title = {Generalizations of {Rolle}’s {Theorem}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-7390},
	url = {https://www.mdpi.com/2227-7390/12/14/2157},
	doi = {10.3390/math12142157},
	abstract = {The classical Rolle’s theorem establishes the existence of (at least) one zero of the derivative of a continuous one-variable function on a compact interval in the real line, which attains the same value at the extremes, and it is differentiable in the interior of the interval. In this paper, we generalize the statement in four ways. First, we provide a version for functions whose domain is in a locally convex topological Hausdorff vector space, which can possibly be infinite-dimensional. Then, we deal with the functions defined in a real interval: we consider the case of unbounded intervals, the case of functions endowed with a weak derivative, and, finally, we consider the case of distributions over an open interval in the real line.},
	language = {en},
	number = {14},
	urldate = {2024-08-23},
	journal = {Mathematics},
	author = {Fiorenza, Alberto and Fiorenza, Renato},
	month = jan,
	year = {2024},
	note = {Number: 14
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Gateaux differential, Lagrange’s theorem, Rolle’s theorem, classic derivative, distributions, locally convex topological Hausdorff vector space, weak derivative},
	pages = {2157},
}

@article{furi_multidimensional_1995,
	title = {A {Multidimensional} {Version} of {Rolle}'s {Theorem}},
	volume = {102},
	issn = {0002-9890},
	url = {https://www.jstor.org/stable/2975011},
	doi = {10.2307/2975011},
	number = {3},
	urldate = {2024-08-23},
	journal = {The American Mathematical Monthly},
	author = {Furi, Massimo and Martelli, Mario},
	year = {1995},
	note = {Publisher: Mathematical Association of America},
	pages = {243--249},
}

@book{apostol_mathematical_1974,
	address = {Reading, Mass.},
	edition = {2nd edition},
	title = {Mathematical {Analysis}, {Second} {Edition}},
	isbn = {978-0-201-00288-1},
	abstract = {It provides a transition from elementary calculus to advanced courses in real and complex function theory and introduces the reader to some of the abstract thinking that pervades modern analysis.},
	language = {English},
	publisher = {Pearson},
	author = {Apostol, Tom},
	month = jan,
	year = {1974},
}

@book{rudin_principles_1976,
	address = {New York},
	edition = {Third edition.},
	series = {International series in pure and applied mathematics.},
	title = {Principles of mathematical analysis},
	isbn = {978-0-07-054235-8},
	abstract = {The third edition of this well known text continues to provide a solid foundation in mathematical analysis for undergraduate and first-year graduate students. The text begins with a discussion of the real number system as a complete ordered field. (Dedekind's construction is now treated in an appendix to Chapter I.) The topological background needed for the development of convergence, continuity, differentiation and integration is provided in Chapter 2. There is a new section on the gamma function, and many new and interesting exercises are included. -- Publisher description.},
	language = {eng},
	publisher = {McGraw-Hill},
	author = {Rudin, Walter},
	year = {1976},
	keywords = {Análisis matemático, Mathematical analysis, Mathematics},
}

@article{noauthor_eight_2024,
	chapter = {Technology},
	title = {Eight {US} newspapers sue {OpenAI} and {Microsoft} for copyright infringement},
	issn = {0261-3077},
	url = {https://www.theguardian.com/technology/2024/apr/30/us-newspaper-openai-lawsuit},
	abstract = {The Chicago Tribune, Denver Post and others file suit saying the tech companies ‘purloin millions’ of articles without permission},
	language = {en-GB},
	urldate = {2024-08-21},
	journal = {The Guardian},
	month = apr,
	year = {2024},
	keywords = {Artificial intelligence (AI), ChatGPT, Media, Microsoft, Newspapers, Newspapers \& magazines, OpenAI, Technology, US news},
}

@article{noauthor_music_2024,
	chapter = {Music},
	title = {Music labels sue {AI} song generators {Suno} and {Udio} for copyright infringement},
	issn = {0261-3077},
	url = {https://www.theguardian.com/music/article/2024/jun/25/record-labels-sue-ai-song-generator-apps-copyright-infringement-lawsuit},
	abstract = {Software steals songs to ‘spit out’ similar tunes, lawsuit says, asking for \$150,000 a work in compensation},
	language = {en-GB},
	urldate = {2024-08-21},
	journal = {The Guardian},
	month = jun,
	year = {2024},
	keywords = {Artificial intelligence (AI), Culture, Intellectual property, Law, Law (US), Music, Music industry, Technology, US news},
}

@article{brittain_music_2024,
	chapter = {Litigation},
	title = {Music {AI} startups {Suno} and {Udio} slam record label lawsuits in court filings},
	url = {https://www.reuters.com/legal/litigation/music-ai-startups-suno-udio-slam-record-label-lawsuits-court-filings-2024-08-01/},
	abstract = {The companies said using copyrighted sound recordings to train their systems qualifies as fair use under U.S. copyright law, and they called the lawsuits attempts to stifle independent competition.},
	language = {en},
	urldate = {2024-08-21},
	journal = {Reuters},
	author = {Brittain, Blake},
	month = aug,
	year = {2024},
}

@book{zhou_machine_2021,
	address = {Gateway East, Singapore},
	title = {Machine learning},
	isbn = {9789811519673},
	language = {eng},
	publisher = {Springer},
	author = {Zhou, Zhi-Hua},
	year = {2021},
	keywords = {Machine learning},
}

@book{ross_first_2019,
	address = {New York, New York},
	edition = {10th ed.},
	title = {A first course in probability},
	isbn = {978-0-13-475311-9},
	abstract = {"This book is intended as an elementary introduction to the theory of probability for students in mathematics, statistics, engineering, and the sciences (including computer science, biology, the social sciences, and management science) who possess the prerequisite knowledge of elementary calculus. This edition includes new and updated problems, exercises, and text material chosen both for inherent interest and for their use in building student intuition about probability."--Preface, pp. x-xi.},
	language = {eng},
	publisher = {Pearson},
	author = {Ross, Sheldon M.},
	year = {2019},
	keywords = {Probabilities\$\$QProbabilities, Textbooks},
}

@misc{openai_gpt-4_2024,
	title = {{GPT}-4 {Technical} {Report}},
	url = {http://arxiv.org/abs/2303.08774},
	doi = {10.48550/arXiv.2303.08774},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	urldate = {2024-08-12},
	publisher = {arXiv},
	author = {OpenAI and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and Bernadett-Shapiro, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Simón Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and Gontijo-Lopes, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, Łukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, Łukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and McGrew, Bob and McKinney, Scott Mayer and McLeavey, Christine and McMillan, Paul and McNeil, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and Mély, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cerón and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
	month = mar,
	year = {2024},
	note = {arXiv:2303.08774 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{cole_leaked_2024,
	title = {Leaked: {Nvidia}'s {AI} {Scraping} {Pipeline}},
	shorttitle = {Leaked},
	url = {https://www.404media.co/email/241e8e1c-1858-4adc-a4b9-3be54cb1ea88/},
	abstract = {Internal emails, Slack conversations and documents obtained by 404 Media show how Nvidia created a yet-to-be-released video foundational model.},
	language = {en},
	urldate = {2024-08-13},
	journal = {404 Media},
	author = {Cole, Samantha},
	month = aug,
	year = {2024},
}

@misc{gershgorn_githubs_2021,
	title = {{GitHub}’s automatic coding tool rests on untested legal ground - {The} {Verge}},
	url = {https://www.theverge.com/2021/7/7/22561180/github-copilot-legal-copyright-fair-use-public-code},
	urldate = {2024-08-10},
	author = {Gershgorn, Dave},
	month = jul,
	year = {2021},
}

@article{mullin_inside_2023,
	chapter = {Business},
	title = {Inside the {News} {Industry}’s {Uneasy} {Negotiations} {With} {OpenAI}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2023/12/29/business/media/media-openai-chatgpt.html},
	abstract = {Several major publishers have been in talks to license content to the creator of ChatGPT, but agreement on the price and terms has been elusive.},
	language = {en-US},
	urldate = {2024-08-12},
	journal = {The New York Times},
	author = {Mullin, Benjamin},
	month = dec,
	year = {2023},
	keywords = {Artificial Intelligence, Associated Press, Atlanta Journal-Constitution, Axel Springer Verlag AG, ChatGPT, Computers and the Internet, Copyrights and Copyright Violations, Microsoft Corp, New York Times, News Corporation, News Media Alliance, News and News Media, Newspapers, OpenAI Labs, Prices (Fares, Fees and Rates), Springer, Axel, Verlag AG, Suits and Litigation (Civil), Wall Street Journal, Washington Post},
}

@article{skiljic_when_2021,
	title = {When {Art} {Meets} {Technology} or {Vice} {Versa}: {Key} {Challenges} at the {Crossroads} of {AI}-{Generated} {Artworks} and {Copyright} {Law}},
	volume = {52},
	issn = {0018-9855, 2195-0237},
	shorttitle = {When {Art} {Meets} {Technology} or {Vice} {Versa}},
	url = {https://link.springer.com/article/10.1007/s40319-021-01119-w},
	doi = {10.1007/s40319-021-01119-w},
	abstract = {This paper discusses the intersection of Artificial Intelligence (AI) and copyright law in the art domain, stressing the dominant problems and polemics that arise, such as authorship, originality and creativity, use of copyrightable content as input data to train and teach AI to generate artwork and the liability for AI-induced copyright infringements. In the first section, this paper provides an overview of the current advancement of AI and the necessary human contribution to generate artwork. The second section analyses doctrinal aspects of originality and creativity, aiming to exemplify how AI-generated artwork cannot be subsumed under traditional interpretations of these concepts, which should be reinterpreted to fit AI-generated artworks. This paper further discusses the issue of authorship of AI-generated artworks and aims to point out that this issue should be the extent to whom, of the many humans involved, the authorship should be attributed. The fourth section analyses the use of copyright content to train and teach AI to generate artwork, possible infringements of the right of reproduction and the right of adaptation, and the applicability of exceptions in that respect, and also proposes a collective licensing scheme to tackle this issue. The fifth section analyses the loophole of who is liable for AI-induced copyright infringements, concepts of copyright liability and sanctions, and suggests the assignment of liability to human(s) with decisive influence over the infringing algorithm(s). Finally, this paper discusses whether AI should be granted (limited) legal personhood and, if opting for this and if enforceable, aims to tackle the foregoing issues. The European Union perspective on copyright is in the focus of this paper, referring to the Croatian legal system, where needed or appropriate. The United States' copyright system is also referenced.},
	language = {English},
	number = {10},
	urldate = {2024-08-12},
	journal = {IIC-INTERNATIONAL REVIEW OF INTELLECTUAL PROPERTY AND COMPETITION LAW},
	author = {Skiljic, Alina},
	month = nov,
	year = {2021},
	note = {Num Pages: 32
Place: Heidelberg
Publisher: Springer Heidelberg
Web of Science ID: WOS:000708345500001},
	keywords = {AI, Authorship, Copyright, Copyright infringement, Croatia, EU, Legal personhood, Liability, Originality, Reproduction rights, US},
	pages = {1338--1369},
}

@article{drott_copyright_2021,
	title = {Copyright, compensation, and commons in the music {AI} industry},
	volume = {14},
	issn = {1751-0694, 1751-0708},
	url = {https://www.tandfonline.com/doi/full/10.1080/17510694.2020.1839702},
	doi = {10.1080/17510694.2020.1839702},
	abstract = {Since 2015 a number of startups has emerged seeking to commercialise music AI. Two types of firm stand out. One markets services directly to consumers, in the form of adaptive music that responds to contextual and/or activity-related cues; another group markets AI-generated music to cultural producers, in the form of algorithmically-generated, royalty-free production music. Initiatives like these have generated debate among legal scholars about notions of copyright and authorship. But until recently discussion has focused on who (or what) should be awarded rights over the products of so-called 'expressive AI': Its programmers? Its users? Or the AI itself? Largely overlooked in such debates is the status of another repertoire: not the music put out by an AI, but that which is put into it, the music that constitutes the training set necessary for machine learners to learn. Given the massive datasets mobilised to train machine learners, existing copyright regimes prove inadequate in the face of the questions of distributive justice that such commercial systems raise. Specifically, commercial practices premised on the extraction of value from a special kind of common-pool resource - the shared knowledge of a given music community - demand remedies grounded not in the methodological individualism of copyright law, but commons-based responses instead. As such, the article sketches a couple of alternative models (levy-based trust funds, ownership funds) that could provide a more equitable institutional and economic framework for sustaining the musical commons.},
	language = {English},
	number = {2},
	urldate = {2024-08-12},
	journal = {CREATIVE INDUSTRIES JOURNAL},
	author = {Drott, Eric},
	month = aug,
	year = {2021},
	note = {Num Pages: 18
Place: Abingdon
Publisher: Taylor \& Francis Ltd
Web of Science ID: WOS:000704605200006},
	keywords = {MACHINE, Music, artificial intelligence, commons, copyright, machine learning},
	pages = {190--207},
}

@article{geiger_elaborating_2024,
	title = {Elaborating a {Human} {Rights}-{Friendly} {Copyright} {Framework} for {Generative} {AI}},
	issn = {0018-9855, 2195-0237},
	url = {https://link.springer.com/article/10.1007/s40319-024-01481-5},
	doi = {10.1007/s40319-024-01481-5},
	abstract = {As works are increasingly produced by machines using artificial intelligence (AI) systems, with a result that is often difficult to distinguish from that of a human creator, the question of what should be the appropriate response of the legal system and, in particular, of the copyright system has become central. If the generator of copyright protection has traditionally been the author's creative input, AI forces us to reassess what in the creative process is special in human creativity and where the creative input lies in AI-generated works. But it also poses more fundamental questions on what the copyright system should achieve and who/what it should protect. In particular, since many human authors will potentially face the competition of these AI machines on the market, new ways of remunerating creators will have to be imagined while making sure that the copyright system does not stand in the way of these important technological developments.This contribution analyses the copyright issues related to so-called "generative AI" systems and reviews the arguments currently being advanced to change the copyright regime for AI-generated works. To do so, the underlying human rights framing intellectual property laws are used as the starting point from which a balanced copyright framework for generative AI could (and even should) be derived. It follows from the applicable human rights framework for copyright, but also from the anthropocentric approach of human rights, that the protection of creators and human creativity must be considered the point of reference when assessing future reforms with regard to copyright and generative AI systems. This approach establishes generative AI systems as an instrument of the human creator - and not as a substitute. It also reinforces the notion that copyright should be a tool to protect creativity and creators, not a legal mechanism to secure the amortization of economic investments in AI technology. As a consequence, it is argued that the copyrightability of AI-generated outputs should be considered with utmost care and only when AI is used as a technical tool for creators in their creation process - in other words, when they can serve a human author. At the same time, AI systems are here to stay, and their development should not be inhibited, as they can have many beneficial aspects (including for creators) if appropriately regulated.The right to train generative AI systems via machine learning technology can be derived from the right to science and culture and freedom of (artistic) expression (Arts. 19 and 27(1) Universal Declaration of Human Rights (UDHR); Art. 15(1)(a) and (b) International Covenant on Economic, Social and Cultural Rights (ICESCR); Arts. 11 and 13 EU Charter of Fundamental Rights (EUCFR)), as AI can lead to useful advances in science and the arts; moreover, it is important for human creators to be able to use outputs produced by generative AI in their creative process. This grounding is even stronger when the training is conducted for research purposes, as the training process can then also benefit from the fundamental right-to-research justification. However, since a large quantity of copyrighted works is required for the training of generative AI systems, a remuneration obligation for these uses arises from a human rights perspective, in particular when AI systems have a commercial purpose. It follows from the right to the protection of the creator's moral and material interests (Arts. 27(2) and 17 UDHR, 15(1)(c) ICESCR; 17(2) EUCFR, 1 Protocol No. 1, 8 European Convention on Human Rights (ECHR)) that authors must be adequately remunerated for the commercial use of their works unless there is a strong justification legitimizing the use. For this reason, it is proposed that the machine learning process using copyright-protected works to train the AI gives rise to a limitation-based remuneration right to the benefit of human creators. The article also briefly explores if and when the moral interest of creators deriving from human rights protection could justify their opposition to the use of their work for the purpose of training AI systems. It is argued that the weaker the fundamental rights claim to train the AI is, the stronger the moral rights claim could be. For example, training an AI to produce works for discriminatory or racist purposes will benefit from a weaker (if any) fundamental rights protection, but will potentially raise important moral concerns of the author of the work used for training purposes.More generally, the article concludes that in order to secure a vibrant space for culture and creativity, (finally) cherishing and putting the Human Author at the center of the copyright system is necessary (and not only to erect fences to the benefit of copyright industries, which could be the unfortunate result of the recent first broad regulatory intervention on AI by the EU, the so-called "Artificial Intelligence Act"). In doing so, it might be possible in the future to have AI-systems that serve creators and creativity, and not the other way around.},
	language = {English},
	urldate = {2024-08-12},
	journal = {IIC-INTERNATIONAL REVIEW OF INTELLECTUAL PROPERTY AND COMPETITION LAW},
	author = {Geiger, Christophe},
	month = jun,
	year = {2024},
	note = {Num Pages: 37
Place: Heidelberg
Publisher: Springer Heidelberg
Web of Science ID: WOS:001238475100001},
	keywords = {AI, COURT, Copyright, FUNDAMENTAL RIGHTS, Human rights, INTELLECTUAL PROPERTY, JUSTICE, LAW, MACHINE, REFORM, Remuneration rights, TEXT},
}

@article{samuelson_generative_2023,
	title = {Generative {AI} meets copyright},
	volume = {381},
	url = {https://www.science.org/doi/10.1126/science.adi0656},
	doi = {10.1126/science.adi0656},
	number = {6654},
	urldate = {2024-08-12},
	journal = {Science},
	author = {Samuelson, Pamela},
	month = jul,
	year = {2023},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {158--161},
}

@inproceedings{zhang_privacy_2024,
	title = {Privacy and copyright protection in generative ai: {A} lifecycle perspective},
	shorttitle = {Privacy and copyright protection in generative ai},
	doi = {10.1145/3644815.3644952},
	abstract = {The advent of Generative AI has marked a significant milestone in artificial intelligence, demonstrating remarkable capabilities in generating realistic images, texts, and data patterns. However, these advancements come with heightened concerns over data privacy and copyright infringement, primarily due to the reliance on vast datasets for model training. Traditional approaches like differential privacy, machine unlearning, and data poisoning only offer fragmented solutions to these complex issues. Our paper delves into the multifaceted challenges of privacy and copyright protection within the data lifecycle. We advocate for integrated approaches that combines technical innovation with ethical foresight, holistically addressing these concerns by investigating and devising solutions that are informed by the lifecycle perspective. This work aims to catalyze a broader discussion and inspire concerted efforts towards data privacy and copyright integrity in Generative AI. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	author = {Zhang, D. and Xia, B. and Liu, Y. and Xu, X. and Hoang, T. and Xing, Z. and Staples, M. and Lu, Q. and Zhu, L.},
	year = {2024},
	keywords = {copyrights, data lifecycle, generative AI, privacy, software architecture, software engineering for AI},
	pages = {92--97},
}

@article{wan_copyright_2021,
	title = {Copyright protection for {AI}-generated outputs: {The} experience from {China}},
	volume = {42},
	issn = {02673649},
	shorttitle = {Copyright protection for {AI}-generated outputs},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364921000546},
	doi = {10.1016/j.clsr.2021.105581},
	abstract = {Artificial intelligence (AI) is involved more frequently in the creative process nowadays, which raises debates associated with copyright protection for its outputs across the globe, China included. On 25 April 2019, the Beijing Internet Court released the first decision in relation to the copyrightability of the output automatically generated by computer software in China. In this case, the Beijing Internet Court held that copyrightable works should be created by natural persons, and therefore denied copyright protection for the output intelligently generated by computer software although it possessed originality. In another case decided on 24 December 2019, the Nanshan District Court of Shenzhen approved that the output automatically generated by computer software was copyrightable, holding that the review generated by an intelligent writing software conformed to the formal requirements of written works and it could be granted copyright protection.},
	language = {en},
	urldate = {2024-08-12},
	journal = {Computer Law \& Security Review},
	author = {Wan, Yong and Lu, Hongxuyang},
	month = sep,
	year = {2021},
	pages = {105581},
}

@incollection{yu_challenges_2021,
	title = {Challenges of artificial intelligence to patent law and copyright law and countermeasures1},
	abstract = {This chapter explores the degree of adaptability of truly aspects of the patent and copyright systems such as the objects of protection, qualification of the right holder, ownership of patent or copyright, judgment of infringement, and subjects of liability, in a new AI era when AI algorithms independently make inventions and create literary and artistic works based on their deep learning ability. Then explores the role of the patent and the copyright law system as to the extent that they accord with the principle of fairness, both for the current “Weak AI era” and the future “Strong AI era”. Based on case studies, this chapter analyses a series of challenges brought by the development of AI technology to the current patent law and copyright law, try to suggest some possible solutions including but not limited to changing the primary rights, adding secondary rights, Sui Generis Right and new exceptions and limitations. © The Editor and Contributors Severally 2021.},
	booktitle = {The {Future} of {Intellectual} {Property}},
	author = {Yu, X. and Zhang, R. and Zhang, B. and Wang, H.},
	year = {2021},
	pages = {150--168},
}

@article{matulionyte_can_2023,
	title = {Can {AI} infringe moral rights of authors and should we do anything about it? {An} {Australian} perspective},
	volume = {15},
	shorttitle = {Can {AI} infringe moral rights of authors and should we do anything about it?},
	doi = {10.1080/17579961.2023.2184138},
	abstract = {While artificial intelligence technologies (AI), such as machine learning (ML), hold significant potential for the economy and social wellbeing, it is unclear to what extent copyright laws stimulate or impede the development of these promising technologies. The unauthorised use of copyright-protected works in the ML process and its possible implications on economic rights of authors have been previously explored, however, the implications of such use on the moral rights of authors–the rights of attribution and integrity–have not been examined. This paper, by focusing on Australia as a case study, explores whether the use of works as training data in the ML process could amount to the infringement of moral rights of authors and, if so, whether law reform in the area is needed. © 2023 Informa UK Limited, trading as Taylor \& Francis Group.},
	number = {1},
	journal = {Law, Innovation and Technology},
	author = {Matulionyte, R.},
	year = {2023},
	keywords = {Copyright, artificial intelligence, machine learning, moral rights, proportionality},
	pages = {124--147},
}

@inproceedings{kenthapadi_generative_2023,
	title = {Generative {AI} meets {Responsible} {AI}: {Practical} {Challenges} and {Opportunities}},
	shorttitle = {Generative {AI} meets {Responsible} {AI}},
	doi = {10.1145/3580305.3599557},
	abstract = {Generative AI models and applications are being rapidly developed and deployed across a wide spectrum of industries and applications ranging from writing and email assistants to graphic design and art generation to educational assistants to coding to drug discovery. However, there are several ethical and social considerations associated with generative AI models and applications. These concerns include lack of interpretability, bias and discrimination, privacy, lack of model robustness, fake and misleading content, copyright implications, plagiarism, and environmental impact associated with training and inference of generative AI models. In this tutorial, we first motivate the need for adopting responsible AI principles when developing and deploying large language models (LLMs) and other generative AI models, as part of a broader AI model governance and responsible AI framework, from societal, legal, user, and model developer perspectives, and provide a roadmap for thinking about responsible AI for generative AI in practice. We provide a brief technical overview of text and image generation models, and highlight the key responsible AI desiderata associated with these models. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We focus on real-world generative AI use cases spanning domains such as media generation, writing assistants, copywriting, code generation, and conversational assistants, present practical solution approaches / guidelines for applying responsible AI techniques effectively, discuss lessons learned from deploying responsible AI approaches for generative AI applications in practice, and highlight the key open research problems. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on responsible AI in the context of generative AI, and pave the way for building more reliable and trustworthy generative AI applications in the future. © 2023 Owner/Author.},
	author = {Kenthapadi, K. and Lakkaraju, H. and Rajani, N.},
	year = {2023},
	keywords = {case studies from industry, ethics in ai, generative ai models and applications, large language models, responsible ai},
	pages = {5805--5806},
}

@article{albakjaji_dilemma_2024,
	title = {The {Dilemma} of the {Copyrights} of {Artificial} {Intelligence}: {The} {Case} of {Saudi} {Arabia} {Regulations}},
	volume = {16},
	shorttitle = {The {Dilemma} of the {Copyrights} of {Artificial} {Intelligence}},
	doi = {10.4018/IJSKD.336920},
	abstract = {Artificial intelligence (AI) and intellectual property (IP) share some key similarities, such as uncertainty in predictions, processing a massive amount of data, and machine learning. Yet, they also differ from each other. This paper provides background information on how these two domains have evolved over time. It also highlights how Saudi Arabia’s IP system differs from those of other countries. Furthermore, this article explores the relationship between AI and IP and their application in copyright. This study is significant as it helps identify the challenges and opportunities that AI presents with respect to IP in terms of copyright. Finally, this article makes recommendations that will help protect both AI and IP. © 2024 IGI Global. All rights reserved.},
	number = {1},
	journal = {International Journal of Sociotechnology and Knowledge Development},
	author = {Albakjaji, M. and Almarzouqi, R.},
	year = {2024},
	keywords = {Artificial Intelligence, Copyright, Legal Framework, Saudi Arabia},
}

@article{kuai_ai_2022,
	title = {{AI} ≥ {Journalism}: {How} the {Chinese} {Copyright} {Law} {Protects} {Tech} {Giants}’ {AI} {Innovations} and {Disrupts} the {Journalistic} {Institution}},
	volume = {10},
	shorttitle = {{AI} ≥ {Journalism}},
	doi = {10.1080/21670811.2022.2120032},
	abstract = {Journalism and other institutions clash over automated news generation, algorithmic distribution and content ownership worldwide. AI policies are the main mechanisms that establish and organise the hierarchies among these institutions. Few studies, however, have explored the normative dimension of AI in policymaking in journalism, especially beyond the West. This case study inspects the copyright law’s impact on AI innovation in newsrooms in the unexamined Chinese context. Using neo-institutional theory and policy network theory, the study investigates the Third Amendment to the Chinese Copyright Law, exemplary court cases regarding automated journalism copyright disputes (such as Tencent v. Yingxun and Film v. Baidu), and other supporting documents. The findings show how China’s copyright legal framework separates authorship and ownership; defines “originality” and “creativity” in human-machine collaboration; and prioritises tech companies while undermining journalistic autonomy. We argue that the law’s eager embrace of AI may give tech companies an advantage over news organisations that do not necessarily have a strategy to adopt AI. Moreover, it favours state-owned, resource-rich official media over the private sector. An implication of this shifting power dynamic is the possibility of privately owned news media being marginalised, resulting in even stronger state control over media production and information flow. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor \& Francis Group.},
	number = {10},
	journal = {Digital Journalism},
	author = {Kuai, J. and Ferrer-Conill, R. and Karlsson, M.},
	year = {2022},
	keywords = {Artificial intelligence, China, automated news, copyright law, institutional theory, journalism, media innovation, policy network},
	pages = {1893--1912},
}

@article{peukert_economics_nodate,
	title = {The economics of copyright in the digital age},
	volume = {n/a},
	copyright = {© 2024 The Authors. Journal of Economic Surveys published by John Wiley \& Sons Ltd.},
	issn = {1467-6419},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12632},
	doi = {10.1111/joes.12632},
	abstract = {Intellectual property rights are fundamental to how economies organize innovation and steer the diffusion of knowledge. Copyright law, in particular, has developed constantly to keep up with emerging technologies and the interests of creators, consumers, and intermediaries of the different creative industries. We provide a synthesis of the literature on the law and economics of copyright in the digital age, with a particular focus on the available empirical evidence. First, we discuss the legal foundations of the copyright system and developments of length and scope throughout the era of digitization. Second, we review the literature on technological change with its opportunities and challenges for the stakeholders involved. We give special attention to empirical evidence on online copyright enforcement, changes in the supply of works due to digital technology, and the importance of creative re-use and new licensing and business models. We then set out avenues for further research identifying critical gaps in the literature regarding the scope of empirical copyright research, the effects of technology that enables algorithmic licensing, and copyright issues related to software, data and artificial intelligence.},
	language = {en},
	number = {n/a},
	urldate = {2024-08-12},
	journal = {Journal of Economic Surveys},
	author = {Peukert, Christian and Windisch, Margaritha},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/joes.12632},
	keywords = {artificial intelligence, business models, copyright, digitization, enforcement, evidence, licensing, technology},
}

@incollection{craig_chapter_2022,
	title = {Chapter 7: {The} {AI}-copyright challenge: tech-neutrality, authorship, and the public interest},
	isbn = {978-1-80088-190-7},
	shorttitle = {Chapter 7},
	url = {https://www.elgaronline.com/edcollchap/book/9781800881907/book-part-9781800881907-13.xml},
	abstract = {Many of copyright's core concepts - from authorship and ownership to infringement and fair use - are being challenged by the rapid rise of generative AI. Whether in service of creativity or capital, however, copyright law is perfectly capable of absorbing this latest innovation. More interesting than the doctrinal debates that AI provokes, then, is the opportunity it presents to revisit the purposes of the copyright system in the age of AI. After introducing the AI-copyright challenge, the chapter considers the guiding principles and normative objectives that underlie - and so ought to inform - copyright law and its response to AI technologies. It proposes a substantive approach to tech-neutrality aimed at achieving normative equilibrium in the face of technological disruption. Applying this frame - with its corresponding emphasis on authorship and the public interest - the chapter goes on to explain why AI-generated outputs are therefore uncopyrightable and AI-training inputs are non-infringing.},
	language = {en},
	urldate = {2024-08-12},
	author = {Craig, Carys J.},
	month = dec,
	year = {2022},
	note = {Section: Research Handbook on Intellectual Property and Artificial Intelligence},
}

@article{mr_intikhab_alam_legal_2018,
	title = {The {Legal} {Ramifications} of {AI}-{Powered} {News} {Systems} and {Copyright} on {Media} {Practices}},
	volume = {2},
	issn = {2456-6470},
	url = {https://www.ijtsrd.com/other-scientific-research-area/other/18350/the-legal-ramifications-of-aipowered-news-systems-and-copyright-on-media-practices/mr-intikhab-alam-shamsi},
	abstract = {Since 2010, automated news, or artificial intelligence system (AIS)-assisted generation of news articles, has been created. It encompasses a number of approaches that require varying degrees of data, software, and human engagement. This may have several effects on the implementation of intellectual property and copyright law. Using comparative legal methodologies, we investigate their consequences for certain legal categories, such as authorship (and, by extension, needed originality) and kinds of works, including collaborative, derivative, and, most notably, communal works. Sui generis and adjacent rights are also examined for their applicability to AIS-aided news productions. Our primary conclusion is that the economics intellectual property rights are protected by collaborative works in any situation. We suggest a shorter period before a work enters the public domain. There is still a space for greater authoritarian and personal rights. However, it demonstrates more difficulties when it comes to moral rights, particularly in Common Law nations.},
	language = {en},
	number = {5},
	urldate = {2024-08-12},
	journal = {International Journal of Trend in Scientific Research and Development},
	author = {Mr. Intikhab Alam, Shamsi},
	month = aug,
	year = {2018},
	note = {Number: 5
Publisher: IJTSRD},
	pages = {2512--2520},
}

@article{trapova_robojournalism_2022,
	title = {Robojournalism – {A} {Copyright} {Study} on the {Use} of {Artificial} {Intelligence} in the {European} {News} {Industry}},
	volume = {71},
	issn = {2632-8623},
	url = {https://doi.org/10.1093/grurint/ikac038},
	doi = {10.1093/grurint/ikac038},
	abstract = {The copyright protectability of outputs generated by, or with the help of Artificial Intelligence (AI) is a hotly debated question in academia and by many institutions. In practice, sophisticated AI algorithms have become a meaningful assistant in the European news industry for the reporting of sports (Retresco’s collaboration with the German Football Association), weather (textOmatic’s collaboration with FOCUS Online) and finance (the Guardian’s ‘Guarbot’). Furthermore, for the first time in copyright history a court in China assessed the validity of a company’s copyright claim over the articles produced by the corporation’s algorithm. The protection with copyright of this ‘robojournalism’ is no longer just a buzzwordy trend. From a technological perspective, robojournalism currently relies on assistive, generative and distributive technologies. The first two seem to be the most problematic from a copyright perspective as they challenge the well-rooted human authorship requirement. Experts have been able to agree so far that it does not look like AI technology is going to be a disruptive force in the media industry. However, researching the impact of AI in journalism matters a great deal. There are numerous benefits stemming from the use of AI in the newsroom – from expanding news coverage, through faster content production, all the way to leaving journalists more time for the more ‘creative’ and investigative tasks where the algorithm remains weak. This paper addresses, first, the protectability of the outputs of robojournalism under the existing European Union copyright laws. It then goes on to introduce findings related to the practical significance of robojournalism in the European news industry. Here, our focus is on the business, media, and communications studies’ perspectives of automated journalism. Our results demonstrate that the extent to which European journalism relies on assistive and generative technologies to produce written output does not justify, from a copyright perspective, the changing of the current anthropocentric copyright system. These findings have wider implications as AI-generated outputs have prompted many to talk about market failure if copyright (or related rights) protection was to be refused for such works.1},
	number = {7},
	urldate = {2024-08-12},
	journal = {GRUR International},
	author = {Trapova, Alina and Mezei, Péter},
	month = jul,
	year = {2022},
	pages = {589--602},
}

@article{sturm_artificial_2019,
	title = {Artificial {Intelligence} and {Music}: {Open} {Questions} of {Copyright} {Law} and {Engineering} {Praxis}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-0752},
	shorttitle = {Artificial {Intelligence} and {Music}},
	url = {https://www.mdpi.com/2076-0752/8/3/115},
	doi = {10.3390/arts8030115},
	abstract = {The application of artificial intelligence (AI) to music stretches back many decades, and presents numerous unique opportunities for a variety of uses, such as the recommendation of recorded music from massive commercial archives, or the (semi-)automated creation of music. Due to unparalleled access to music data and effective learning algorithms running on high-powered computational hardware, AI is now producing surprising outcomes in a domain fully entrenched in human creativity—not to mention a revenue source around the globe. These developments call for a close inspection of what is occurring, and consideration of how it is changing and can change our relationship with music for better and for worse. This article looks at AI applied to music from two perspectives: copyright law and engineering praxis. It grounds its discussion in the development and use of a specific application of AI in music creation, which raises further and unanticipated questions. Most of the questions collected in this article are open as their answers are not yet clear at this time, but they are nonetheless important to consider as AI technologies develop and are applied more widely to music, not to mention other domains centred on human creativity.},
	language = {en},
	number = {3},
	urldate = {2024-08-12},
	journal = {Arts},
	author = {Sturm, Bob L. T. and Iglesias, Maria and Ben-Tal, Oded and Miron, Marius and Gómez, Emilia},
	month = sep,
	year = {2019},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial intelligence, copyright, engineering, ethics, music},
	pages = {115},
}

@article{shroff_ai_2024,
	title = {{AI} \& {Copyright}: {A} {Case} {Study} of the {Music} {Industry}},
	volume = {2},
	copyright = {Copyright (c) 2024 Lila Shroff},
	issn = {2996-5837},
	shorttitle = {{AI} \& {Copyright}},
	url = {https://ojs.stanford.edu/ojs/index.php/grace/article/view/3226},
	abstract = {Recently, artists of all types have been questioning what generative AI means for their livelihoods. Historically, progress in technology has led to fear of displacement among artists—the advent of photography was felt as a great threat by portrait painters. However, despite historical precedents, a novel question emerges in the way that generative AI systems are trained. Namely, the training of these systems requires models to be fed incomprehensibly large amounts of data which results in copyrighted materials being used. When models are operated by commercial agents, we must ask ourselves: what should the rights be of the human actors who have produced creative work which is used—without their permission or credit—to train AI systems deployed for the financial gain of others? Answering these questions will help regulators to create better policies and lead technologists to design more human-centered technology. Already, many legal scholars, technologists, and corporate lawyers have offered opinions on this topic. However, missing from this conversation are the voices of actual creative workers themselves. In the following paper, I develop a set of principles outlining what the rights of artists should be with respect to the use of their work in the training and deployment of generative AI systems. Namely, I examine the music industry to understand artists’ perspectives in order to arrive at principles of (a) increased inter-stakeholder communication, (b) dataset transparency requirements, (c) the ability for an artist to opt out of a training dataset, and (d) fair application of “fair use” law.},
	language = {en},
	number = {1},
	urldate = {2024-08-12},
	journal = {GRACE: Global Review of AI Community Ethics},
	author = {Shroff, Lila},
	month = jan,
	year = {2024},
	note = {Number: 1},
}

@misc{mcgee_chatgpt_2023,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {{ChatGPT} and {Copyright} {Infringement}: {An} {Exploratory} {Study}},
	shorttitle = {{ChatGPT} and {Copyright} {Infringement}},
	url = {https://papers.ssrn.com/abstract=4578430},
	doi = {10.2139/ssrn.4578430},
	abstract = {Writers of both fiction and nonfiction have expressed concern over the possibility that ChatGPT might infringe on their copyrighted material, thus reducing or eliminating their income stream. The present study tests the current state of AI technology by asking ChatGPT to print the first paragraph of an actual novel. It is then asked to provide certain information regarding the contents of the novel, such as genre, plot, the names of the protagonist and his girlfriend, the city where the novel takes place, the protagonist’s job title and the name of his employer. On the first round of questions, ChatGPTs answers were uniformly incorrect. The second round of questions produced equally incorrect answers. ChatGPT was then asked to write a few alternative endings to the novel once it was given some additional information about the novel’s plot and contents. The endings were written quite well, although not much detail was given. Based on this exploratory study, it appears that ChatGPT does not pose much of a threat to intellectual property at this time. However, that could change in the future.},
	language = {en},
	urldate = {2024-08-12},
	author = {McGee, Robert W.},
	month = sep,
	year = {2023},
	keywords = {AI, ChatGPT, artificial intelligence, copyright, intellectual property},
}

@incollection{bonadio_chapter_2022,
	title = {Chapter 13: {Can} artificial intelligence infringe copyright? {Some} reflections},
	isbn = {978-1-80088-190-7},
	shorttitle = {Chapter 13},
	url = {https://www.elgaronline.com/edcollchap/book/9781800881907/book-part-9781800881907-19.xml},
	abstract = {Creative machines consume. They often devour huge amounts of data as part of learning processes including books, photographs, images, articles, social media feeds, videos and other kinds of content - data are the building blocks of algorithmic creativity. Programs that generate music, for example, are fed with huge quantities of source material, from hits at the top of the charts to lesser-known pieces, which they assess with a view to finding patterns. This inevitably raises risks of copyright infringement - both in relation to the inputs and outputs of the AI system - as a substantial amount of the data used may be subject to protection. Who should be liable for infringement? Are any exceptions to infringement available in these circumstances? Should we avoid a binary regime whereby algorithmic creativity is given a more generous fair use or fair dealing treatment? In this contribution, we explore the above questions with a focus on key jurisdictions including the UK, EU and the United States.},
	language = {en},
	urldate = {2024-08-12},
	author = {Bonadio, Enrico and Dinev, Plamen and McDonagh, Luke},
	month = dec,
	year = {2022},
	note = {Section: Research Handbook on Intellectual Property and Artificial Intelligence},
}

@article{murray_generative_2023,
	title = {Generative {AI} {Art}: {Copyright} {Infringement} and {Fair} {Use}},
	volume = {26},
	shorttitle = {Generative {AI} {Art}},
	url = {https://heinonline.org/HOL/P?h=hein.journals/comlrtj26&i=273},
	language = {eng},
	number = {2},
	urldate = {2024-08-12},
	journal = {SMU Science and Technology Law Review},
	author = {Murray, Michael D.},
	year = {2023},
	pages = {259--316},
}

@article{gillotte_copyright_2019,
	title = {Copyright {Infringement} in {AI}-{Generated} {Artworks} {Note}},
	volume = {53},
	url = {https://heinonline.org/HOL/P?h=hein.journals/davlr53&i=2676},
	language = {eng},
	number = {5},
	urldate = {2024-08-12},
	journal = {UC Davis Law Review},
	author = {Gillotte, Jessica L.},
	year = {2019},
	pages = {2655--2692},
}

@misc{e2analyst_gpt-4_2023,
	title = {{GPT}-4: {Everything} you want to know about {OpenAI}’s new {AI} model},
	shorttitle = {{GPT}-4},
	url = {https://medium.com/predict/gpt-4-everything-you-want-to-know-about-openais-new-ai-model-a5977b42e495},
	abstract = {From Text to Images, GPT-4 is Set to Revolutionize the Way We Interact with AI},
	language = {en},
	urldate = {2024-08-12},
	journal = {Predict},
	author = {E2Analyst},
	month = mar,
	year = {2023},
}

@misc{noauthor_gpt-4_2024,
	title = {{GPT}-4},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=GPT-4&oldid=1236785652},
	abstract = {Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models. It was launched on March 14, 2023, and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI's API, and via the free chatbot Microsoft Copilot.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and "data licensed from third-party providers" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.: 2 
Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4, equipped with vision capabilities (GPT-4V), is capable of taking images as input on ChatGPT. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.},
	language = {en},
	urldate = {2024-08-12},
	journal = {Wikipedia},
	month = jul,
	year = {2024},
	note = {Page Version ID: 1236785652},
}

@inproceedings{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	volume = {33},
	url = {https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	urldate = {2024-08-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year = {2020},
	pages = {1877--1901},
}

@inproceedings{radford_language_2019,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	url = {https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe},
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
	urldate = {2024-08-12},
	author = {Radford, Alec and Wu, Jeff and Child, R. and Luan, D. and Amodei, Dario and Sutskever, I.},
	year = {2019},
}

@inproceedings{radford_improving_2018,
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	url = {https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	urldate = {2024-08-12},
	author = {Radford, Alec and Narasimhan, Karthik},
	year = {2018},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	volume = {25},
	url = {https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	urldate = {2024-08-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	year = {2012},
}

@misc{dai_tunneling_2018,
	title = {Tunneling {Neural} {Perception} and {Logic} {Reasoning} through {Abductive} {Learning}},
	url = {http://arxiv.org/abs/1802.01173},
	doi = {10.48550/arXiv.1802.01173},
	abstract = {Perception and reasoning are basic human abilities that are seamlessly connected as part of human intelligence. However, in current machine learning systems, the perception and reasoning modules are incompatible. Tasks requiring joint perception and reasoning ability are difficult to accomplish autonomously and still demand human intervention. Inspired by the way language experts decoded Mayan scripts by joining two abilities in an abductive manner, this paper proposes the abductive learning framework. The framework learns perception and reasoning simultaneously with the help of a trial-and-error abductive process. We present the Neural-Logical Machine as an implementation of this novel learning framework. We demonstrate that--using human-like abductive learning--the machine learns from a small set of simple hand-written equations and then generalizes well to complex equations, a feat that is beyond the capability of state-of-the-art neural network models. The abductive learning framework explores a new direction for approaching human-level learning ability.},
	urldate = {2024-08-12},
	publisher = {arXiv},
	author = {Dai, Wang-Zhou and Xu, Qiu-Ling and Yu, Yang and Zhou, Zhi-Hua},
	month = feb,
	year = {2018},
	note = {arXiv:1802.01173 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{wan_copyright_2021-1,
	title = {Copyright protection for {AI}-generated outputs: {The} experience from {China}},
	volume = {42},
	issn = {0267-3649},
	shorttitle = {Copyright protection for {AI}-generated outputs},
	url = {https://www.sciencedirect.com/science/article/pii/S0267364921000546},
	doi = {10.1016/j.clsr.2021.105581},
	abstract = {Artificial intelligence (AI) is involved more frequently in the creative process nowadays, which raises debates associated with copyright protection for its outputs across the globe, China included. On 25 April 2019, the Beijing Internet Court released the first decision in relation to the copyrightability of the output automatically generated by computer software in China. In this case, the Beijing Internet Court held that copyrightable works should be created by natural persons, and therefore denied copyright protection for the output intelligently generated by computer software although it possessed originality. In another case decided on 24 December 2019, the Nanshan District Court of Shenzhen approved that the output automatically generated by computer software was copyrightable, holding that the review generated by an intelligent writing software conformed to the formal requirements of written works and it could be granted copyright protection. This article analyses these two cases in detail and describes the experience of China in copyright protection for AI-generated outputs. As the first two cases about copyrightability of AI-generated outputs in China, the two cases play a significant role in future copyright protection of such outputs nationally and internationally. The two cases indicate that some of AI-generated outputs are eligible for copyright protection in China. Instead of challenging the existing doctrines of modern copyright regime, the two decisions provide a mechanism for copyright protection of AI-generated outputs within the current human-centered copyright law realm.},
	urldate = {2024-08-10},
	journal = {Computer Law \& Security Review},
	author = {Wan, Yong and Lu, Hongxuyang},
	month = sep,
	year = {2021},
	keywords = {AI-generated output, Chinese Copyright Law, Copyright, Human intervention, Originality, Ownership},
	pages = {105581},
}

@misc{noauthor_wikipedialarge_2024,
	title = {Wikipedia:{Large} language models and copyright},
	copyright = {Creative Commons Attribution-ShareAlike License},
	shorttitle = {Wikipedia},
	url = {https://en.wikipedia.org/w/index.php?title=Wikipedia:Large_language_models_and_copyright&oldid=1224445929#Does_LLM_output_inherently_violate_copyright_law?},
	abstract = {An LLM can generate copyright-violating material. Generated text may include verbatim snippets from non-free content or be a derivative work. In addition, using LLMs to summarize copyrighted content (like news articles) may produce excessively close paraphrases.
The copyright status of LLMs trained on copyrighted material is not yet fully understood. Their output may not be compatible with the CC BY-SA license and the GNU license used for text published on Wikipedia.},
	language = {en},
	urldate = {2024-08-10},
	journal = {Wikipedia},
	month = may,
	year = {2024},
	note = {Page Version ID: 1224445929},
}

@misc{meeus_copyright_2024,
	title = {Copyright {Traps} for {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2402.09363},
	doi = {10.48550/arXiv.2402.09363},
	abstract = {Questions of fair use of copyright-protected content to train Large Language Models (LLMs) are being actively debated. Document-level inference has been proposed as a new task: inferring from black-box access to the trained model whether a piece of content has been seen during training. SOTA methods however rely on naturally occurring memorization of (part of) the content. While very effective against models that memorize significantly, we hypothesize--and later confirm--that they will not work against models that do not naturally memorize, e.g. medium-size 1B models. We here propose to use copyright traps, the inclusion of fictitious entries in original content, to detect the use of copyrighted materials in LLMs with a focus on models where memorization does not naturally occur. We carefully design a randomized controlled experimental setup, inserting traps into original content (books) and train a 1.3B LLM from scratch. We first validate that the use of content in our target model would be undetectable using existing methods. We then show, contrary to intuition, that even medium-length trap sentences repeated a significant number of times (100) are not detectable using existing methods. However, we show that longer sequences repeated a large number of times can be reliably detected (AUC=0.75) and used as copyright traps. Beyond copyright applications, our findings contribute to the study of LLM memorization: the randomized controlled setup enables us to draw causal relationships between memorization and certain sequence properties such as repetition in model training data and perplexity.},
	urldate = {2024-08-10},
	publisher = {arXiv},
	author = {Meeus, Matthieu and Shilov, Igor and Faysse, Manuel and de Montjoye, Yves-Alexandre},
	month = jun,
	year = {2024},
	note = {arXiv:2402.09363 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security},
}

@article{lucchi_chatgpt_2023,
	title = {{ChatGPT}: {A} {Case} {Study} on {Copyright} {Challenges} for {Generative} {Artificial} {Intelligence} {Systems}},
	issn = {1867-299X, 2190-8249},
	shorttitle = {{ChatGPT}},
	url = {https://www.cambridge.org/core/journals/european-journal-of-risk-regulation/article/chatgpt-a-case-study-on-copyright-challenges-for-generative-artificial-intelligence-systems/CEDCE34DED599CC4EB201289BB161965},
	doi = {10.1017/err.2023.59},
	abstract = {This article focuses on copyright issues pertaining to generative artificial intelligence (AI) systems, with particular emphasis on the ChatGPT case study as a primary exemplar. In order to generate high-quality outcomes, generative AI systems require substantial quantities of training data, which may frequently comprise copyright-protected information. This prompts inquiries into the legal principles of fair use, the creation of derivative works and the lawfulness of data gathering and utilisation. The utilisation of input data for the purpose of training and enhancing AI models presents significant concerns regarding potential violations of copyright. This paper offers suggestions for safeguarding the interests of copyright holders and competitors, while simultaneously addressing legal challenges and expediting the advancement of AI technologies. This study analyses the ChatGPT platform as a case example to explore the necessary modifications that copyright regulations must undergo to adequately tackle the intricacies of authorship and ownership in the realm of AI-generated creative content.},
	language = {en},
	urldate = {2024-08-10},
	journal = {European Journal of Risk Regulation},
	author = {Lucchi, Nicola},
	month = aug,
	year = {2023},
	keywords = {Artificial intelligence, ChatGPT, copyright, data sharing, intellectual property, language models, training data},
	pages = {1--23},
}

@article{chmielewski_adobe_2023,
	chapter = {Technology},
	title = {Adobe, {Nvidia} {AI} imagery systems aim to resolve copyright questions},
	url = {https://www.reuters.com/technology/adobe-nvidia-ai-imagery-systems-aim-resolve-copyright-questions-2023-03-21/},
	abstract = {Two Silicon Valley companies on Tuesday announced new tools that use artificial intelligence to generate images while tackling some of the thorniest legal issues surrounding the technology: copyrights and payments.},
	language = {en},
	urldate = {2024-08-10},
	journal = {Reuters},
	author = {Chmielewski, Dawn and Nellis, Stephen},
	month = mar,
	year = {2023},
}

@article{seawright_case_2008,
	title = {Case {Selection} {Techniques} in {Case} {Study} {Research}: {A} {Menu} of {Qualitative} and {Quantitative} {Options}},
	volume = {61},
	issn = {1065-9129},
	shorttitle = {Case {Selection} {Techniques} in {Case} {Study} {Research}},
	url = {https://doi.org/10.1177/1065912907313077},
	doi = {10.1177/1065912907313077},
	abstract = {How can scholars select cases from a large universe for in-depth case study analysis? Random sampling is not typically a viable approach when the total number of cases to be selected is small. Hence attention to purposive modes of sampling is needed. Yet, while the existing qualitative literature on case selection offers a wide range of suggestions for case selection, most techniques discussed require in-depth familiarity of each case. Seven case selection procedures are considered, each of which facilitates a different strategy for within-case analysis. The case selection procedures considered focus on typical, diverse, extreme, deviant, influential, most similar, and most different cases. For each case selection procedure, quantitative approaches are discussed that meet the goals of the approach, while still requiring information that can reasonably be gathered for a large number of cases.},
	language = {en},
	number = {2},
	urldate = {2024-08-10},
	journal = {Political Research Quarterly},
	author = {Seawright, Jason and Gerring, John},
	month = jun,
	year = {2008},
	note = {Publisher: SAGE Publications Inc},
	pages = {294--308},
}

@article{kretschmer_copyright_2024,
	title = {Copyright {Law} and the {Lifecycle} of {Machine} {Learning} {Models}},
	volume = {55},
	issn = {2195-0237},
	url = {https://doi.org/10.1007/s40319-023-01419-3},
	doi = {10.1007/s40319-023-01419-3},
	abstract = {Machine learning, a subfield of artificial intelligence (AI), relies on large corpora of data as input for learning algorithms, resulting in trained models that can perform a variety of tasks. While data or information are not subject matter within copyright law, almost all materials used to construct corpora for machine learning are protected by copyright law: texts, images, videos, and so on. There are global policy moves to address the copyright implications of machine learning, in particular in the context of so-called “foundation models” that underpin generative AI. This paper takes a step back, exploring empirically three technological settings through detailed case studies. We set out the established industry methodology of a lifecycle of AI (collecting data, organising data, model training, model operation) to arrive at descriptions suitable for legal analysis. This will allow an assessment of the challenges for a harmonisation of rights, exceptions and disclosure under EU copyright law. The three case studies are:1.Machine learning for scientific purposes, in the context of a study of regional short-term letting markets;2.Natural Language Processing (NLP), in the context of large language models;3.Computer vision, in the context of content moderation of images.},
	language = {en},
	number = {1},
	urldate = {2024-08-10},
	journal = {IIC - International Review of Intellectual Property and Competition Law},
	author = {Kretschmer, Martin and Margoni, Thomas and Oruç, Pinar},
	month = jan,
	year = {2024},
	keywords = {Artificial intelligence, Copyright, Data mining, Digital single market, EU, Text mining},
	pages = {110--138},
}

@misc{bommasani_opportunities_2022,
	title = {On the {Opportunities} and {Risks} of {Foundation} {Models}},
	url = {http://arxiv.org/abs/2108.07258},
	doi = {10.48550/arXiv.2108.07258},
	abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	urldate = {2024-08-10},
	publisher = {arXiv},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	month = jul,
	year = {2022},
	note = {arXiv:2108.07258 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@misc{wei_evaluating_2024,
	title = {Evaluating {Copyright} {Takedown} {Methods} for {Language} {Models}},
	url = {http://arxiv.org/abs/2406.18664},
	doi = {10.48550/arXiv.2406.18664},
	abstract = {Language models (LMs) derive their capabilities from extensive training on diverse data, including potentially copyrighted material. These models can memorize and generate content similar to their training data, posing potential concerns. Therefore, model creators are motivated to develop mitigation methods that prevent generating protected content. We term this procedure as copyright takedowns for LMs, noting the conceptual similarity to (but legal distinction from) the DMCA takedown This paper introduces the first evaluation of the feasibility and side effects of copyright takedowns for LMs. We propose CoTaEval, an evaluation framework to assess the effectiveness of copyright takedown methods, the impact on the model's ability to retain uncopyrightable factual knowledge from the training data whose recitation is embargoed, and how well the model maintains its general utility and efficiency. We examine several strategies, including adding system prompts, decoding-time filtering interventions, and unlearning approaches. Our findings indicate that no tested method excels across all metrics, showing significant room for research in this unique problem setting and indicating potential unresolved challenges for live policy proposals.},
	urldate = {2024-08-10},
	publisher = {arXiv},
	author = {Wei, Boyi and Shi, Weijia and Huang, Yangsibo and Smith, Noah A. and Zhang, Chiyuan and Zettlemoyer, Luke and Li, Kai and Henderson, Peter},
	month = jul,
	year = {2024},
	note = {arXiv:2406.18664 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{kalman_generalized_1984,
	title = {The {Generalized} {Vandermonde} {Matrix}},
	volume = {57},
	issn = {0025-570X},
	url = {https://www.tandfonline.com/doi/abs/10.1080/0025570X.1984.11977069},
	doi = {10.1080/0025570X.1984.11977069},
	number = {1},
	urldate = {2024-08-08},
	journal = {Mathematics Magazine},
	author = {Kalman, Dan},
	month = jan,
	year = {1984},
	pages = {15--21},
}

@article{rushanan_vandermonde_1989,
	title = {On the {Vandermonde} {Matrix}},
	volume = {96},
	issn = {0002-9890},
	url = {https://doi.org/10.1080/00029890.1989.11972306},
	doi = {10.1080/00029890.1989.11972306},
	number = {10},
	urldate = {2024-08-08},
	journal = {The American Mathematical Monthly},
	author = {Rushanan, Joseph J.},
	month = dec,
	year = {1989},
	pages = {921--924},
}

@misc{noauthor_vandermonde_2024,
	title = {Vandermonde matrix},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Vandermonde_matrix&oldid=1221855303#Third_proof:_row_and_column_operations},
	abstract = {In linear algebra, a Vandermonde matrix, named after Alexandre-Théophile Vandermonde, is a matrix with the terms of a geometric progression in each row: an 
  
    
      
        (
        m
        +
        1
        )
        ×
        (
        n
        +
        1
        )
      
    
    \{{\textbackslash}displaystyle (m+1){\textbackslash}times (n+1)\}
  
 matrix

  
    
      
        V
        =
        V
        (
        
          x
          
            0
          
        
        ,
        
          x
          
            1
          
        
        ,
        ⋯
        ,
        
          x
          
            m
          
        
        )
        =
        
          
            [
            
              
                
                  1
                
                
                  
                    x
                    
                      0
                    
                  
                
                
                  
                    x
                    
                      0
                    
                    
                      2
                    
                  
                
                
                  …
                
                
                  
                    x
                    
                      0
                    
                    
                      n
                    
                  
                
              
              
                
                  1
                
                
                  
                    x
                    
                      1
                    
                  
                
                
                  
                    x
                    
                      1
                    
                    
                      2
                    
                  
                
                
                  …
                
                
                  
                    x
                    
                      1
                    
                    
                      n
                    
                  
                
              
              
                
                  1
                
                
                  
                    x
                    
                      2
                    
                  
                
                
                  
                    x
                    
                      2
                    
                    
                      2
                    
                  
                
                
                  …
                
                
                  
                    x
                    
                      2
                    
                    
                      n
                    
                  
                
              
              
                
                  ⋮
                
                
                  ⋮
                
                
                  ⋮
                
                
                  ⋱
                
                
                  ⋮
                
              
              
                
                  1
                
                
                  
                    x
                    
                      m
                    
                  
                
                
                  
                    x
                    
                      m
                    
                    
                      2
                    
                  
                
                
                  …
                
                
                  
                    x
                    
                      m
                    
                    
                      n
                    
                  
                
              
            
            ]
          
        
      
    
    \{{\textbackslash}displaystyle V=V(x\_\{0\},x\_\{1\},{\textbackslash}cdots ,x\_\{m\})=\{{\textbackslash}begin\{bmatrix\}1\&x\_\{0\}\&x\_\{0\}{\textasciicircum}\{2\}\&{\textbackslash}dots \&x\_\{0\}{\textasciicircum}\{n\}{\textbackslash}{\textbackslash}1\&x\_\{1\}\&x\_\{1\}{\textasciicircum}\{2\}\&{\textbackslash}dots \&x\_\{1\}{\textasciicircum}\{n\}{\textbackslash}{\textbackslash}1\&x\_\{2\}\&x\_\{2\}{\textasciicircum}\{2\}\&{\textbackslash}dots \&x\_\{2\}{\textasciicircum}\{n\}{\textbackslash}{\textbackslash}{\textbackslash}vdots \&{\textbackslash}vdots \&{\textbackslash}vdots \&{\textbackslash}ddots \&{\textbackslash}vdots {\textbackslash}{\textbackslash}1\&x\_\{m\}\&x\_\{m\}{\textasciicircum}\{2\}\&{\textbackslash}dots \&x\_\{m\}{\textasciicircum}\{n\}{\textbackslash}end\{bmatrix\}\}\}
  

with entries 
  
    
      
        
          V
          
            i
            ,
            j
          
        
        =
        
          x
          
            i
          
          
            j
          
        
      
    
    \{{\textbackslash}displaystyle V\_\{i,j\}=x\_\{i\}{\textasciicircum}\{j\}\}
  
, the jth power of the number 
  
    
      
        
          x
          
            i
          
        
      
    
    \{{\textbackslash}displaystyle x\_\{i\}\}
  
, for all zero-based indices 
  
    
      
        i
      
    
    \{{\textbackslash}displaystyle i\}
  
 and 
  
    
      
        j
      
    
    \{{\textbackslash}displaystyle j\}
  
. Some authors define the Vandermonde matrix as the transpose of the above matrix.
The determinant of a square Vandermonde matrix (when 
  
    
      
        n
        =
        m
      
    
    \{{\textbackslash}displaystyle n=m\}
  
) is called a Vandermonde determinant or Vandermonde polynomial. Its value is:

  
    
      
        det
        (
        V
        )
        =
        
          ∏
          
            0
            ≤
            i
            {\textless}
            j
            ≤
            n
          
        
        (
        
          x
          
            j
          
        
        −
        
          x
          
            i
          
        
        )
        .
      
    
    \{{\textbackslash}displaystyle {\textbackslash}det(V)={\textbackslash}prod \_\{0{\textbackslash}leq i{\textless}j{\textbackslash}leq n\}(x\_\{j\}-x\_\{i\}).\}
  

This is non-zero if and only if all 
  
    
      
        
          x
          
            i
          
        
      
    
    \{{\textbackslash}displaystyle x\_\{i\}\}
  
 are distinct (no two are equal), making the Vandermonde matrix invertible.},
	language = {en},
	urldate = {2024-08-08},
	journal = {Wikipedia},
	month = may,
	year = {2024},
	note = {Page Version ID: 1221855303},
}

@article{li_vandermonde_2023,
	title = {Vandermonde {Determinant} and {Its} {Applications}},
	volume = {7},
	doi = {10.22158/jecs.v7n4p16},
	abstract = {Vandermonde determinant is an important object in linear algebra, which has special and elegant structure, and admits the significant applications in many different areas. In this paper, we summarize two typical proofs and present many applications of Vandermonde determinant.},
	journal = {Journal of Education and Culture Studies},
	author = {Li, Yanjun and Ding, Xiaoye},
	month = oct,
	year = {2023},
	pages = {p16},
}

@article{ji_survey_2023,
	title = {Survey of {Hallucination} in {Natural} {Language} {Generation}},
	volume = {55},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3571730},
	doi = {10.1145/3571730},
	abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before. In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
	number = {12},
	urldate = {2024-01-18},
	journal = {ACM Computing Surveys},
	author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
	month = mar,
	year = {2023},
	note = {SC: 0000954},
	keywords = {/unread, Hallucination, consistency in NLG, extrinsic hallucination, factuality in NLG, faithfulness in NLG, intrinsic hallucination},
	pages = {248:1--248:38},
}

@inproceedings{collobert_unified_2008,
	address = {New York, NY, USA},
	series = {{ICML} '08},
	title = {A unified architecture for natural language processing: deep neural networks with multitask learning},
	isbn = {978-1-60558-205-4},
	shorttitle = {A unified architecture for natural language processing},
	url = {https://doi.org/10.1145/1390156.1390177},
	doi = {10.1145/1390156.1390177},
	abstract = {We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.},
	urldate = {2024-01-17},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning},
	publisher = {Association for Computing Machinery},
	author = {Collobert, Ronan and Weston, Jason},
	month = jul,
	year = {2008},
	note = {SC: 0007406},
	keywords = {/unread, Word2Vec},
	pages = {160--167},
}

@inproceedings{mikolov_neural_2009,
	title = {Neural network based language models for highly inflective languages},
	url = {https://ieeexplore.ieee.org/abstract/document/4960686},
	doi = {10.1109/icassp.2009.4960686},
	abstract = {Speech recognition of inflectional and morphologically rich languages like Czech is currently quite a challenging task, because simple n-gram techniques are unable to capture important regularities in the data. Several possible solutions were proposed, namely class based models, factored models, decision trees and neural networks. This paper describes improvements obtained in recognition of spoken Czech lectures using language models based on neural networks. Relative reductions in word error rate are more than 15\% over baseline obtained with adapted 4-gram backoff language model using modified Kneser-Ney smoothing.},
	urldate = {2024-01-18},
	booktitle = {2009 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Mikolov, Tomas and Kopecky, Jiri and Burget, Lukas and Glembek, Ondrej and ?Cernocky, Jan},
	month = apr,
	year = {2009},
	note = {SC: 0000163 
ISSN: 2379-190X},
	keywords = {/unread},
	pages = {4725--4728},
}

@article{westerlund_emergence_2019,
	title = {The {Emergence} of {Deepfake} {Technology}: {A} {Review}},
	volume = {9},
	issn = {1927-0321},
	shorttitle = {The {Emergence} of {Deepfake} {Technology}},
	doi = {10.22215/timreview/1282},
	number = {11},
	journal = {Technology Innovation Management Review},
	author = {Westerlund, Mika},
	year = {2019},
	note = {Place: Ottawa
Publisher: Talent First Network},
	pages = {40--53},
}

@misc{huh_platonic_2024,
	title = {The {Platonic} {Representation} {Hypothesis}},
	url = {http://arxiv.org/abs/2405.07987},
	doi = {10.48550/arXiv.2405.07987},
	abstract = {We argue that representations in AI models, particularly deep networks, are converging. First, we survey many examples of convergence in the literature: over time and across multiple domains, the ways by which different neural networks represent data are becoming more aligned. Next, we demonstrate convergence across data modalities: as vision models and language models get larger, they measure distance between datapoints in a more and more alike way. We hypothesize that this convergence is driving toward a shared statistical model of reality, akin to Plato's concept of an ideal reality. We term such a representation the platonic representation and discuss several possible selective pressures toward it. Finally, we discuss the implications of these trends, their limitations, and counterexamples to our analysis.},
	urldate = {2024-07-25},
	publisher = {arXiv},
	author = {Huh, Minyoung and Cheung, Brian and Wang, Tongzhou and Isola, Phillip},
	month = jul,
	year = {2024},
	note = {arXiv:2405.07987 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	copyright = {2015 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	language = {en},
	number = {7553},
	urldate = {2024-07-06},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Mathematics and computing},
	pages = {436--444},
}

@misc{noauthor__nodate,
	title = {明安图是卡塔兰数的首创者 - 中国知网},
	url = {https://chn.oversea.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFD8589&filename=NMGX198802004&uniplatform=OVERSEA&v=-659YyCr7isEXU_REA8DrW60hOdEI2RDeHixfHmmDkHFO21GDn3AJF-UsbEKCP-Q},
	urldate = {2024-06-21},
}

@article{spichal_using_2024,
	title = {Using the {Golden} {Section} to {Approximate} π},
	volume = {97},
	issn = {0025-570X},
	url = {https://doi.org/10.1080/0025570X.2024.2336868},
	doi = {10.1080/0025570X.2024.2336868},
	abstract = {We derive one specific example of a Machin-like formula for approximating π using the unit circle and the reciproval of the golden section. The efficiency of our derived formula is compared to other, similar formulas using Lehmer’s measure.},
	number = {3},
	urldate = {2024-06-21},
	journal = {Mathematics Magazine},
	author = {Spíchal, Luděk},
	month = may,
	year = {2024},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/0025570X.2024.2336868},
	keywords = {11B39},
	pages = {315--320},
}

@article{ross_dedekind_2024,
	title = {Dedekind {Cuts}, {Moving} {Markers}, and the {Uncountability} of ℝ},
	volume = {97},
	issn = {0025-570X},
	url = {https://doi.org/10.1080/0025570X.2024.2336439},
	doi = {10.1080/0025570X.2024.2336439},
	abstract = {We give short proofs that ℝ is uncountable directly from the definition of ℝ as the set of Dedekind cuts of ℚ.},
	number = {3},
	urldate = {2024-06-21},
	journal = {Mathematics Magazine},
	author = {Ross, David A.},
	month = may,
	year = {2024},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/0025570X.2024.2336439},
	keywords = {03E99},
	pages = {286--292},
}

@article{pudwell_catalan_2024,
	title = {Catalan {Numbers} and {Permutations}},
	volume = {97},
	issn = {0025-570X},
	url = {https://doi.org/10.1080/0025570X.2024.2336423},
	doi = {10.1080/0025570X.2024.2336423},
	abstract = {The Catalan numbers are the solution to hundreds of interesting counting problems. We consider a set of permutations counted not by the Catalan numbers, but by the squares of the Catalan numbers. While their enumeration is already known by more technical methods, we present a new proof by giving a bijection with pairs of arrangements of parentheses.},
	number = {3},
	urldate = {2024-06-21},
	journal = {Mathematics Magazine},
	author = {Pudwell, Lara},
	month = may,
	year = {2024},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/0025570X.2024.2336423},
	keywords = {05A05},
	pages = {279--283},
}

@misc{noauthor_how_2024,
	title = {How to spot a deepfake - {SoSafe}},
	url = {https://sosafe-awareness.com/blog/how-to-spot-a-deepfake/},
	abstract = {The accuracy of deepfakes escalates at terrifying speeds. Let’s look into what exactly deepfakes are \& how we can protect ourselves against them.},
	language = {en-GB},
	urldate = {2024-06-01},
	month = feb,
	year = {2024},
	note = {Section: Human Risk Management},
}

@misc{noauthor_deepfake_2024,
	title = {‘{Deepfake}’ of {Biden}’s {Voice} {Called} {Early} {Example} of {US} {Election} {Disinformation}},
	url = {https://learningenglish.voanews.com/a/deepfake-of-biden-s-voice-called-early-example-of-us-election-disinformation/7455392.html},
	abstract = {A fake voice message of U.S. President Joe Biden was recently sent to voters in an effort to persuade voters not to take part in a state primary election. Technology experts describe the call as a fresh effort to confuse voters by presenting false facts as truth.},
	language = {en},
	urldate = {2024-06-01},
	journal = {Voice of America},
	month = jan,
	year = {2024},
}

@misc{krueger_recent_2023,
	title = {Recent {Advancements} {In} {The} {Field} {Of} {Deepfake} {Detection}},
	url = {http://arxiv.org/abs/2308.05563},
	doi = {10.48550/arXiv.2308.05563},
	abstract = {A deepfake is a photo or video of a person whose image has been digitally altered or partially replaced with an image of someone else. Deepfakes have the potential to cause a variety of problems and are often used maliciously. A common usage is altering videos of prominent political figures and celebrities. These deepfakes can portray them making offensive, problematic, and/or untrue statements. Current deepfakes can be very realistic, and when used in this way, can spread panic and even influence elections and political opinions. There are many deepfake detection strategies currently in use but finding the most comprehensive and universal method is critical. So, in this survey we will address the problems of malicious deepfake creation and the lack of universal deepfake detection methods. Our objective is to survey and analyze a variety of current methods and advances in the field of deepfake detection.},
	urldate = {2024-06-01},
	publisher = {arXiv},
	author = {Krueger, Natalie and Vanamala, Dr Mounika and Dave, Dr Rushit},
	month = aug,
	year = {2023},
	note = {arXiv:2308.05563 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
}

@misc{pattison-gortan_courts_2023,
	title = {Courts {Consider} the {Coming} {Risk} of {Deepfake} {Evidence}},
	url = {https://www.govtech.com/products/courts-consider-the-coming-risks-of-deepfake-evidence},
	abstract = {Catching convincing AI-fabricated evidence is still a work in progress, but courts could benefit from thinking now about how they might confront the challenges posed by the emerging technology.},
	language = {en},
	urldate = {2024-05-25},
	journal = {GovTech},
	author = {Pattison-Gortan, Jule},
	month = sep,
	year = {2023},
	note = {Section: Emerging Tech},
}

@misc{surasit_criminal_nodate,
	title = {Criminal exploitation of deepfakes in {South} {East} {Asia}},
	url = {https://globalinitiative.net/analysis/deepfakes-ai-cyber-scam-south-east-asia-organized-crime/},
	abstract = {The Asia-Pacific region saw a 1 530\% increase in deepfake cases between 2022 and 2023, the second highest in the world after North America. Vietnam had the highest increase in deepfake fraud in the region (25.3\%), followed by Japan (23.4\%), and the Philippines saw the highest growth in deepfake cases (4 500\%). AI and deepfakes are also being used in cyber-scam operations across the region, where thousands of people are reported to have been lured to work for organized criminal networks and forced to defraud other people through online scams. As these criminal networks grow, deepfake technology is becoming undoubtedly lucrative.},
	language = {en},
	urldate = {2024-05-25},
	journal = {Global Initiative},
	author = {Surasit, Natnicha},
}

@misc{payne_deepfake_2024,
	title = {Deepfake {\textbar} {History} \& {Facts} {\textbar} {Britannica}},
	url = {https://www.britannica.com/technology/deepfake},
	abstract = {Deepfake, synthetic media, including images, videos, and audio, generated by artificial intelligence (AI) technology that portray something that does not exist in reality or events that have never occurred. The term deepfake combines deep, taken from AI deep-learning technology (a type of machine},
	language = {en},
	urldate = {2024-05-25},
	author = {Payne, Laura},
	month = may,
	year = {2024},
}

@misc{noauthor_deepfakes_2024,
	title = {Deepfakes, explained {\textbar} {MIT} {Sloan}},
	url = {https://mitsloan.mit.edu/ideas-made-to-matter/deepfakes-explained},
	abstract = {What are deepfakes, and how business leaders can learn to identify and protect against them.},
	language = {en},
	urldate = {2024-05-25},
	month = may,
	year = {2024},
}

@misc{mahmud_deep_2023,
	title = {Deep {Insights} of {Deepfake} {Technology} : {A} {Review}},
	shorttitle = {Deep {Insights} of {Deepfake} {Technology}},
	url = {http://arxiv.org/abs/2105.00192},
	doi = {10.48550/arXiv.2105.00192},
	abstract = {Under the aegis of computer vision and deep learning technology, a new emerging techniques has introduced that anyone can make highly realistic but fake videos, images even can manipulates the voices. This technology is widely known as Deepfake Technology. Although it seems interesting techniques to make fake videos or image of something or some individuals but it could spread as misinformation via internet. Deepfake contents could be dangerous for individuals as well as for our communities, organizations, countries religions etc. As Deepfake content creation involve a high level expertise with combination of several algorithms of deep learning, it seems almost real and genuine and difficult to differentiate. In this paper, a wide range of articles have been examined to understand Deepfake technology more extensively. We have examined several articles to find some insights such as what is Deepfake, who are responsible for this, is there any benefits of Deepfake and what are the challenges of this technology. We have also examined several creation and detection techniques. Our study revealed that although Deepfake is a threat to our societies, proper measures and strict regulations could prevent this.},
	urldate = {2024-05-25},
	publisher = {arXiv},
	author = {Mahmud, Bahar Uddin and Sharmin, Afsana},
	month = jan,
	year = {2023},
	note = {arXiv:2105.00192 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{noauthor_deepfake_nodate,
	title = {Deepfake {Technology}},
	url = {https://www.socialmediasafety.org/advocacy/deepfake-technology/},
	abstract = {The Organization for Social Media Safety has sponsored legislation to deter deepfakes that misappropriate identities for pornographic videos.},
	language = {en-US},
	urldate = {2024-05-25},
	journal = {Organization for Social Media Safety},
}

@misc{kelly_explicit_2024,
	title = {Explicit, {AI}-generated {Taylor} {Swift} images spread quickly on social media {\textbar} {CNN} {Business}},
	url = {https://www.cnn.com/2024/01/25/tech/taylor-swift-ai-generated-images/index.html},
	abstract = {Pornographic, AI-generated images of the world’s most famous star spread across social media this week, underscoring the damaging potential posed by mainstream artificial intelligence technology: its ability to create convincingly real and damaging images.},
	language = {en},
	urldate = {2024-05-25},
	journal = {CNN},
	author = {Kelly, Samantha Murphy},
	month = jan,
	year = {2024},
}

@misc{magramo_finance_2024,
	title = {Finance worker pays out \$25 million after video call with deepfake ‘chief financial officer’},
	url = {https://www.cnn.com/2024/02/04/asia/deepfake-cfo-scam-hong-kong-intl-hnk/index.html},
	abstract = {A finance worker at a multinational firm was tricked into paying out \$25 million to fraudsters using deepfake technology to pose as the company’s chief financial officer in a video conference call, according to Hong Kong police.},
	language = {en},
	urldate = {2024-05-25},
	journal = {CNN},
	author = {Magramo, Kathleen, Heather Chen},
	month = feb,
	year = {2024},
}

@misc{eloundou_gpts_2023,
	title = {{GPTs} are {GPTs}: {An} {Early} {Look} at the {Labor} {Market} {Impact} {Potential} of {Large} {Language} {Models}},
	shorttitle = {{GPTs} are {GPTs}},
	url = {http://arxiv.org/abs/2303.10130},
	doi = {10.48550/arXiv.2303.10130},
	abstract = {We investigate the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80\% of the U.S. workforce could have at least 10\% of their work tasks affected by the introduction of LLMs, while approximately 19\% of workers may see at least 50\% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15\% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56\% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock, Daniel},
	month = aug,
	year = {2023},
	note = {SC: 0000334 
arXiv:2303.10130 [cs, econ, q-fin]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Economics - General Economics},
}

@misc{collobert_natural_2011,
	title = {Natural {Language} {Processing} (almost) from {Scratch}},
	url = {http://arxiv.org/abs/1103.0398},
	doi = {10.48550/arXiv.1103.0398},
	abstract = {We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.},
	urldate = {2024-01-18},
	publisher = {arXiv},
	author = {Collobert, Ronan and Weston, Jason and Bottou, Leon and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
	month = mar,
	year = {2011},
	note = {SC: 0009868 
arXiv:1103.0398 [cs]},
	keywords = {/unread, Computer Science - Computation and Language, Computer Science - Machine Learning, Word2Vec},
}

@phdthesis{mikolov2007language,
	type = {phd},
	title = {Language modeling for speech recognition in czech},
	school = {Masters thesis, Brno University of Technology},
	author = {Mikolov, Tomáš},
	year = {2007},
	note = {SC: 0000190 },
	keywords = {/unread},
}

@inproceedings{ratsch_brief_2004,
	title = {A {Brief} {Introduction} into {Machine} {Learning}},
	url = {https://www.semanticscholar.org/paper/A-Brief-Introduction-into-Machine-Learning-R%C3%A4tsch/fab926b5da15870777607679ebd56985735023d0},
	abstract = {The Machine Learning field evolved from the broad field of Artificial Intelligence, which aims to mimic intelligent abilities of humans by machines. In the field of Machine Learningone considers the important question of how to make machines able to “learn”. Learning in this context is understood as inductive inference , where one observesexamplesthat represent incomplete information about some “statistical phenomenon”. Inunsupervisedlearning one typically tries to uncover hidden regularities (e.g. clusters) or to detect anomalies in the data (for instance some unusual machine function or a network intrusion). Insupervised learning , there is alabel associated with each example. It is supposed to be the answer to a question about the example. If the label is discrete, then the task is called classification problem– otherwise, for realvalued labels we speak of a regression problem. Based on these examples (including the labels), one is particularly interested to predict the answer for other cases before they are explicitly observed. Hence, learning is not only a question of remembering but also ofgeneralization to unseen cases .},
	urldate = {2024-01-16},
	author = {Rätsch, G.},
	year = {2004},
	note = {SC: 0000077},
	keywords = {/unread, ⛔ No DOI found},
}

@misc{gu_mamba_2023,
	title = {Mamba: {Linear}-{Time} {Sequence} {Modeling} with {Selective} {State} {Spaces}},
	shorttitle = {Mamba},
	url = {http://arxiv.org/abs/2312.00752},
	doi = {10.48550/arXiv.2312.00752},
	abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5\${\textbackslash}times\$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
	urldate = {2024-01-16},
	publisher = {arXiv},
	author = {Gu, Albert and Dao, Tri},
	month = dec,
	year = {2023},
	note = {SC: 0000011 
arXiv:2312.00752 [cs]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{raschka_model_2020,
	title = {Model {Evaluation}, {Model} {Selection}, and {Algorithm} {Selection} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/1811.12808},
	doi = {10.48550/arXiv.1811.12808},
	abstract = {The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small.},
	urldate = {2024-01-16},
	publisher = {arXiv},
	author = {Raschka, Sebastian},
	month = nov,
	year = {2020},
	note = {SC: 0000026 
arXiv:1811.12808 [cs, stat]},
	keywords = {/unread, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{knight2009bayesian,
	title = {Bayesian inference with tears},
	journal = {Tutorial workbook},
	author = {Knight, Kevin},
	year = {2009},
	keywords = {/unread, ⛔ No DOI found},
}

@article{olah2015understanding,
	title = {Understanding lstm networks},
	author = {Olah, Christopher},
	year = {2015},
	note = {SC: 0001372 },
	keywords = {/unread, ⛔ No DOI found},
}

@misc{staudemeyer_understanding_2019,
	title = {Understanding {LSTM} -- a tutorial into {Long} {Short}-{Term} {Memory} {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1909.09586},
	doi = {10.48550/arXiv.1909.09586},
	abstract = {Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) are one of the most powerful dynamic classifiers publicly known. The network itself and the related learning algorithms are reasonably well documented to get an idea how it works. This paper will shed more light into understanding how LSTM-RNNs evolved and why they work impressively well, focusing on the early, ground-breaking publications. We significantly improved documentation and fixed a number of errors and inconsistencies that accumulated in previous publications. To support understanding we as well revised and unified the notation used.},
	urldate = {2024-01-16},
	publisher = {arXiv},
	author = {Staudemeyer, Ralf C. and Morris, Eric Rothstein},
	month = sep,
	year = {2019},
	note = {SC: 0000686 
arXiv:1909.09586 [cs]},
	keywords = {/unread, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{lafferty_conditional_2001,
	address = {San Francisco, CA, USA},
	series = {{ICML} '01},
	title = {Conditional {Random} {Fields}: {Probabilistic} {Models} for {Segmenting} and {Labeling} {Sequence} {Data}},
	isbn = {978-1-55860-778-1},
	shorttitle = {Conditional {Random} {Fields}},
	urldate = {2024-01-15},
	booktitle = {Proceedings of the {Eighteenth} {International} {Conference} on {Machine} {Learning}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Lafferty, John D. and McCallum, Andrew and Pereira, Fernando C. N.},
	month = jun,
	year = {2001},
	note = {SC: 0018341},
	keywords = {/unread},
	pages = {282--289},
}

@misc{kim_convolutional_2014,
	title = {Convolutional {Neural} {Networks} for {Sentence} {Classification}},
	url = {http://arxiv.org/abs/1408.5882},
	doi = {10.48550/arXiv.1408.5882},
	abstract = {We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.},
	urldate = {2024-01-16},
	publisher = {arXiv},
	author = {Kim, Yoon},
	month = sep,
	year = {2014},
	note = {SC: 0017464 
arXiv:1408.5882 [cs]},
	keywords = {/unread, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{brochier_global_2019,
	address = {New York, NY, USA},
	series = {{WWW} '19},
	title = {Global {Vectors} for {Node} {Representations}},
	isbn = {978-1-4503-6674-8},
	url = {https://doi.org/10.1145/3308558.3313595},
	doi = {10/gf73qp},
	abstract = {Most network embedding algorithms consist in measuring co-occur-rences of nodes via random walks then learning the embeddings using Skip-Gram with Negative Sampling. While it has proven to be a relevant choice, there are alternatives, such as GloVe, which has not been investigated yet for network embedding. Even though SGNS better handles non co-occurrence than GloVe, it has a worse time-complexity. In this paper, we propose a matrix factorization approach for network embedding, inspired by GloVe, that better handles non co-occurrence with a competitive time-complexity. We also show how to extend this model to deal with networks where nodes are documents, by simultaneously learning word, node and document representations. Quantitative evaluations show that our model achieves state-of-the-art performance, while not being so sensitive to the choice of hyper-parameters. Qualitatively speaking, we show how our model helps exploring a network of documents by generating complementary network-oriented and content-oriented keywords.},
	urldate = {2024-01-15},
	booktitle = {The {World} {Wide} {Web} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Brochier, Robin and Guille, Adrien and Velcin, Julien},
	month = may,
	year = {2019},
	note = {SC: 0000059},
	keywords = {/unread, Representation learning, matrix factorization, network embedding},
	pages = {2587--2593},
}

@article{sejnowski_unreasonable_2020,
	title = {The unreasonable effectiveness of deep learning in artificial intelligence},
	volume = {117},
	url = {https://www.pnas.org/doi/10.1073/pnas.1907373117},
	doi = {10/ggv95v},
	abstract = {Deep learning networks have been trained to recognize speech, caption photographs, and translate text between languages at high levels of performance. Although applications of deep learning networks to real-world problems have become ubiquitous, our understanding of why they are so effective is lacking. These empirical results should not be possible according to sample complexity in statistics and nonconvex optimization theory. However, paradoxes in the training and effectiveness of deep learning networks are being investigated and insights are being found in the geometry of high-dimensional spaces. A mathematical theory of deep learning would illuminate how they function, allow us to assess the strengths and weaknesses of different network architectures, and lead to major improvements. Deep learning has provided natural ways for humans to communicate with digital devices and is foundational for building artificial general intelligence. Deep learning was inspired by the architecture of the cerebral cortex and insights into autonomy and general intelligence may be found in other brain regions that are essential for planning and survival, but major breakthroughs will be needed to achieve these goals.},
	number = {48},
	urldate = {2024-01-16},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Sejnowski, Terrence J.},
	month = dec,
	year = {2020},
	note = {SC: 0000359 
Publisher: Proceedings of the National Academy of Sciences},
	keywords = {/unread},
	pages = {30033--30038},
}

@inproceedings{bengio_neural_2000,
	title = {A {Neural} {Probabilistic} {Language} {Model}},
	volume = {13},
	url = {https://proceedings.neurips.cc/paper_files/paper/2000/hash/728f206c2a01bf572b5940d7d9a8fa4c-Abstract.html},
	abstract = {A goal  of statistical language modeling is  to  learn  the joint probability  function of sequences of words.  This is intrinsically difficult because of  the curse of dimensionality:  we propose to fight it with its own weapons.  In the proposed approach one learns simultaneously (1) a distributed rep(cid:173) resentation for each word (i.e.  a similarity between words) along with (2)  the probability function for word sequences, expressed with these repre(cid:173) sentations.  Generalization is  obtained because a sequence of words that  has  never been seen before gets  high probability if it is  made of words  that are similar to words forming an already seen sentence.  We report on  experiments using neural networks for the probability function, showing  on  two  text  corpora that  the  proposed approach  very  significantly  im(cid:173) proves on a state-of-the-art trigram model.},
	urldate = {2024-01-16},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal},
	year = {2000},
	note = {SC: 0010885},
	keywords = {/unread, ⛔ No DOI found},
}

@misc{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	doi = {10.48550/arXiv.1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2024-01-16},
	publisher = {arXiv},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {SC: 0039530 
arXiv:1301.3781 [cs]},
	keywords = {/unread, Computer Science - Computation and Language},
}

@misc{noauthor_addon_nodate,
	title = {Addon {Item}},
	keywords = {/unread},
}

@article{welleck_naturalprover_2022,
	title = {{NaturalProver}: {Grounded} {Mathematical} {Proof} {Generation} with {Language} {Models}},
	volume = {35},
	shorttitle = {{NaturalProver}},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/1fc548a8243ad06616eee731e0572927-Abstract-Conference.html},
	language = {en},
	urldate = {2024-01-13},
	journal = {Advances in Neural Information Processing Systems},
	author = {Welleck, Sean and Liu, Jiacheng and Lu, Ximing and Hajishirzi, Hannaneh and Choi, Yejin},
	month = dec,
	year = {2022},
	note = {SC: 0000021},
	keywords = {/unread, ⛔ No DOI found},
	pages = {4913--4927},
}

@article{fawzi_discovering_2022,
	title = {Discovering faster matrix multiplication algorithms with reinforcement learning},
	volume = {610},
	copyright = {2022 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-022-05172-4},
	doi = {10/gqxw7g},
	abstract = {Improving the efficiency of algorithms for fundamental computations can have a widespread impact, as it can affect the overall speed of a large amount of computations. Matrix multiplication is one such primitive task, occurring in many systems—from neural networks to scientific computing routines. The automatic discovery of algorithms using machine learning offers the prospect of reaching beyond human intuition and outperforming the current best human-designed algorithms. However, automating the algorithm discovery procedure is intricate, as the space of possible algorithms is enormous. Here we report a deep reinforcement learning approach based on AlphaZero1 for discovering efficient and provably correct algorithms for the multiplication of arbitrary matrices. Our agent, AlphaTensor, is trained to play a single-player game where the objective is finding tensor decompositions within a finite factor space. AlphaTensor discovered algorithms that outperform the state-of-the-art complexity for many matrix sizes. Particularly relevant is the case of 4 × 4 matrices in a finite field, where AlphaTensor’s algorithm improves on Strassen’s two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago2. We further showcase the flexibility of AlphaTensor through different use-cases: algorithms with state-of-the-art complexity for structured matrix multiplication and improved practical efficiency by optimizing matrix multiplication for runtime on specific hardware. Our results highlight AlphaTensor’s ability to accelerate the process of algorithmic discovery on a range of problems, and to optimize for different criteria.},
	language = {en},
	number = {7930},
	urldate = {2024-01-13},
	journal = {Nature},
	author = {Fawzi, Alhussein and Balog, Matej and Huang, Aja and Hubert, Thomas and Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and R. Ruiz, Francisco J. and Schrittwieser, Julian and Swirszcz, Grzegorz and Silver, David and Hassabis, Demis and Kohli, Pushmeet},
	month = oct,
	year = {2022},
	note = {SC: 0000334 
Number: 7930
Publisher: Nature Publishing Group},
	keywords = {/unread, Applied mathematics, Computer science},
	pages = {47--53},
}

@article{davies_advancing_2021,
	title = {Advancing mathematics by guiding human intuition with {AI}},
	volume = {600},
	copyright = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-04086-x},
	doi = {10/gnns5p},
	abstract = {The practice of mathematics involves discovering patterns and using these to formulate and prove conjectures, resulting in theorems. Since the 1960s, mathematicians have used computers to assist in the discovery of patterns and formulation of conjectures1, most famously in the Birch and Swinnerton-Dyer conjecture2, a Millennium Prize Problem3. Here we provide examples of new fundamental results in pure mathematics that have been discovered with the assistance of machine learning—demonstrating a method by which machine learning can aid mathematicians in discovering new conjectures and theorems. We propose a process of using machine learning to discover potential patterns and relations between mathematical objects, understanding them with attribution techniques and using these observations to guide intuition and propose conjectures. We outline this machine-learning-guided framework and demonstrate its successful application to current research questions in distinct areas of pure mathematics, in each case showing how it led to meaningful mathematical contributions on important open problems: a new connection between the algebraic and geometric structure of knots, and a candidate algorithm predicted by the combinatorial invariance conjecture for symmetric groups4. Our work may serve as a model for collaboration between the fields of mathematics and artificial intelligence (AI) that can achieve surprising results by leveraging the respective strengths of mathematicians and machine learning.},
	language = {en},
	number = {7887},
	urldate = {2024-01-13},
	journal = {Nature},
	author = {Davies, Alex and Veličković, Petar and Buesing, Lars and Blackwell, Sam and Zheng, Daniel and Tomašev, Nenad and Tanburn, Richard and Battaglia, Peter and Blundell, Charles and Juhász, András and Lackenby, Marc and Williamson, Geordie and Hassabis, Demis and Kohli, Pushmeet},
	month = dec,
	year = {2021},
	note = {SC: 0000320 
Number: 7887
Publisher: Nature Publishing Group},
	keywords = {/unread, Computer science, Pure mathematics, Statistics},
	pages = {70--74},
}

@inproceedings{lewkowycz_solving_2022,
	title = {Solving {Quantitative} {Reasoning} {Problems} with {Language} {Models}},
	url = {https://openreview.net/forum?id=IFXTZERXdM7},
	abstract = {Language models have achieved remarkable performance on a wide range of tasks that require natural language understanding. Nevertheless, state-of-the-art models have generally struggled with tasks that require quantitative reasoning, such as solving mathematics, science, and engineering questions at the college level. To help close this gap, we introduce Minerva, a large language model pretrained on general natural language data and further trained on technical content. The model achieves strong performance in a variety of evaluations, including state-of-the-art performance on the MATH dataset. We also evaluate our model on over two hundred undergraduate-level problems in physics, biology, chemistry, economics, and other sciences that require quantitative reasoning, and find that the model can correctly answer nearly a quarter of them.},
	language = {en},
	urldate = {2024-01-13},
	author = {Lewkowycz, Aitor and Andreassen, Anders Johan and Dohan, David and Dyer, Ethan and Michalewski, Henryk and Ramasesh, Vinay Venkatesh and Slone, Ambrose and Anil, Cem and Schlag, Imanol and Gutman-Solo, Theo and Wu, Yuhuai and Neyshabur, Behnam and Gur-Ari, Guy and Misra, Vedant},
	month = may,
	year = {2022},
	note = {SC: 0000280},
	keywords = {/unread},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
	urldate = {2024-01-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
	note = {SC: 0104270},
	keywords = {/unread, ⛔ No DOI found},
}

@article{chen_multi-view_2024,
	title = {Multi-{View} {Cross}-{Fusion} {Transformer} {Based} on {Kinetic} {Features} for {Non}-{Invasive} {Blood} {Glucose} {Measurement} {Using} {PPG} {Signal}},
	issn = {2168-2208},
	url = {https://ieeexplore.ieee.org/document/10384690},
	doi = {10.1109/JBHI.2024.3351867},
	abstract = {Noninvasive blood glucose (BG) measurement could significantly improve the prevention and management of diabetes. In this paper, we present a robust novel paradigm based on analyzing photoplethysmogram (PPG) signals. The method includes signal pre-processing optimization and a multi-view cross-fusion transformer (MvCFT) network for non-invasive BG assessment. Specifically, a multi-size weighted fitting (MSWF) time-domain filtering algorithm is proposed to optimally preserve the most authentic morphological features of the original signals. Meanwhile, the spatial position encoding-based kinetics features are reconstructed and embedded as prior knowledge to discern the implicit physiological patterns. In addition, a cross-view feature fusion (CVFF) module is designed to incorporate pairwise mutual information among different views to adequately capture the potential complementary features in physiological sequences. Finally, the subject- wise 5- fold cross-validation is performed on a clinical dataset of 260 subjects. The root mean square error (RMSE) and mean absolute error (MAE) of BG measurements are 1.129 mmol/L and 0.659 mmol/L, respectively, and the optimal Zone A in the Clark error grid, representing none clinical risk, is 87.89\%. The results indicate that the proposed method has great potential for homecare applications.},
	urldate = {2024-01-10},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Chen, Shisen and Qin, Fen and Ma, Xuesheng and Wei, Jie and Zhang, Yuan-Ting and Zhang, Yuan and Jovanov, Emil},
	year = {2024},
	note = {Conference Name: IEEE Journal of Biomedical and Health Informatics},
	pages = {1--11},
}

@article{chu_named_2024,
	title = {Named entity recognition in aerospace based on multi-feature fusion transformer},
	volume = {14},
	copyright = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-50705-0},
	doi = {10.1038/s41598-023-50705-0},
	abstract = {In recent years, along with the rapid development in the domain of artificial intelligence and aerospace, aerospace combined with artificial intelligence is the future trend. As an important basic tool for Natural Language Processing, Named Entity Recognition technology can help obtain key relevant knowledge from a large number of aerospace data. In this paper, we produced an aerospace domain entity recognition dataset containing 30 k sentences in Chinese and developed a named entity recognition model that is Multi-Feature Fusion Transformer (MFT), which combines features such as words and radicals to enhance the semantic information of the sentences. In our model, the double Feed-forward Neural Network is exploited as well to ensure MFT better performance. We use our aerospace dataset to train MFT. The experimental results show that MFT has great entity recognition performance, and the F1 score on aerospace dataset is 86.10\%.},
	language = {en},
	number = {1},
	urldate = {2024-01-10},
	journal = {Scientific Reports},
	author = {Chu, Jing and Liu, Yumeng and Yue, Qi and Zheng, Zixuan and Han, Xiaokai},
	month = jan,
	year = {2024},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Aerospace engineering, Computer science, Statistics},
	pages = {827},
}

@article{xiong_stta_2023,
	title = {{STTA}: enhanced text classification via selective test-time augmentation},
	volume = {9},
	issn = {2376-5992},
	shorttitle = {{STTA}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10773867/},
	doi = {10.7717/peerj-cs.1757},
	abstract = {Test-time augmentation (TTA) is a well-established technique that involves aggregating transformed examples of test inputs during the inference stage. The goal is to enhance model performance and reduce the uncertainty of predictions. Despite its advantages of not requiring additional training or hyperparameter tuning, and being applicable to any existing model, TTA is still in its early stages in the field of NLP. This is partly due to the difficulty of discerning the contribution of different transformed samples, which can negatively impact predictions. In order to address these issues, we propose Selective Test-Time Augmentation, called STTA, which aims to select the most beneficial transformed samples for aggregation by identifying reliable samples. Furthermore, we analyze and empirically verify why TTA is sensitive to some text data augmentation methods and reveal why some data augmentation methods lead to erroneous predictions. Through extensive experiments, we demonstrate that STTA is a simple and effective method that can produce promising results in various text classification tasks.},
	urldate = {2024-01-10},
	journal = {PeerJ Computer Science},
	author = {Xiong, Haoyu and Zhang, Xinchun and Yang, Leixin and Xiang, Yu and Zhang, Yaping},
	month = dec,
	year = {2023},
	pmid = {38192474},
	pmcid = {PMC10773867},
	pages = {e1757},
}

@article{fan_kmt-pll_2024,
	title = {{KMT}-{PLL}: {K}-{Means} {Cross}-{Attention} {Transformer} for {Partial} {Label} {Learning}},
	issn = {2162-2388},
	shorttitle = {{KMT}-{PLL}},
	url = {https://ieeexplore.ieee.org/document/10384739},
	doi = {10.1109/TNNLS.2023.3347792},
	abstract = {Partial label learning (PLL) studies the problem of learning instance classification with a set of candidate labels and only one is correct. While recent works have demonstrated that the Vision Transformer (ViT) has achieved good results when training from clean data, its applications to PLL remain limited and challenging. To address this issue, we rethink the relationship between instances and object queries to propose K-means cross-attention transformer for PLL (KMT-PLL), which can continuously learn cluster centers and be used for downstream disambiguation tasks. More specifically, K-means cross-attention as a clustering process can effectively learn the cluster centers to represent label classes. The purpose of this operation is to make the similarity between instances and labels measurable, which can effectively detect noise labels. Furthermore, we propose a new corrected cross entropy formulation, which can assign weights to candidate labels according to the instance-to-label relevance to guide the training of the instance classifier. As the training goes on, the ground-truth label is progressively identified, and the refined labels and cluster centers in turn help to improve the classifier. Simulation results demonstrate the advantage of the KMT-PLL and its suitability for PLL.},
	urldate = {2024-01-10},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Fan, Jinfu and Huang, Linqing and Gong, Chaoyu and You, Yang and Gan, Min and Wang, Zhongjie},
	year = {2024},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	pages = {1--12},
}

@article{peng_enhanced_2024,
	title = {Enhanced matrix inference with {Seq2seq} models via diagonal sorting},
	volume = {14},
	copyright = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-50919-2},
	doi = {10.1038/s41598-023-50919-2},
	abstract = {The effectiveness of sequence-to-sequence (seq2seq) models in natural language processing has been well-established over time, and recent studies have extended their utility by treating mathematical computing tasks as instances of machine translation and achieving remarkable results. However, our exploratory experiments have revealed that the seq2seq model, when employing a generic sorting strategy, is incapable of inferring on matrices of unseen rank, resulting in suboptimal performance. This paper aims to address this limitation by focusing on the matrix-to-sequence process and proposing a novel diagonal-based sorting. The method constructs a stable ordering structure of elements for the shared leading principal submatrix sections in matrices with varying ranks. We conduct experiments involving maximal independent sets and Sudoku laws, comparing seq2seq models utilizing different sorting methods. Our findings demonstrate the advantages of the proposed diagonal-based sorting in inference, particularly when dealing with matrices of unseen ranks. By introducing and advocating for this method, we enhance the suitability of seq2seq models for investigating the laws of matrix inclusion and exploring their potential in solving matrix-related tasks.},
	language = {en},
	number = {1},
	urldate = {2024-01-11},
	journal = {Scientific Reports},
	author = {Peng, Wei and Wang, Yisong and Wu, Maonian},
	month = jan,
	year = {2024},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science},
	pages = {883},
}

@article{alotaibi_computational_2023,
	title = {Computational linguistics based text emotion analysis using enhanced beetle antenna search with deep learning during {COVID}-19 pandemic},
	volume = {9},
	issn = {2376-5992},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10773760/},
	doi = {10.7717/peerj-cs.1714},
	abstract = {Computational intelligence and nature-inspired computing have changed the way biologically and linguistically driven computing paradigms are made. In the last few decades, they have been used more and more to solve optimisation problems in the real world. Computational linguistics has its roots in linguistics, but most of the studies being done today are led by computer scientists. Data-driven and machine-learning methods have become more popular than handwritten language rules, which shows this shift. This study uses a new method called Computational Linguistics-based mood Analysis using Enhanced Beetle Antenna Search with deep learning (CLSA-EBASDL) to tackle the important problem of mood analysis during the COVID-19 pandemic. We sought to determine how people felt about the COVID-19 pandemic by studying social media texts. The method is made up of three main steps. First, data pre-processing changes raw data into a shape that can be used. After that, word embedding is done using the ‘bi-directional encoder representations of transformers (BERT) process. An attention-based bidirectional long short-term memory (ABiLSTM) network is at the heart of mood classification. The Enhanced Beetle Antenna Search (EBAS) method, in particular, fine-tunes hyperparameters so that the ABiLSTM model works at its best. Many tests show that the CLSA-EBASDL method works better than others. Comparative studies show that it works, making it the best method for analysing opinion during the COVID-19 pandemic.},
	urldate = {2024-01-10},
	journal = {PeerJ Computer Science},
	author = {Alotaibi, Youseef and Selvi Sundarapandi, Arun Mozhi and P, Subhashini and Rajendran, Surendran},
	month = dec,
	year = {2023},
	pmid = {38192459},
	pmcid = {PMC10773760},
	pages = {e1714},
}
